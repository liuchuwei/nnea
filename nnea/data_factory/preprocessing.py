"""
æ•°æ®é¢„å¤„ç†æ¨¡å—ï¼ˆna.ppï¼‰
åŒ…å«æ•°æ®æ ‡å‡†åŒ–ã€ç¼ºå¤±å€¼å¤„ç†ã€å¼‚å¸¸å€¼æ£€æµ‹å’Œå¤„ç†ã€åŸºå› /æ ·æœ¬è¿‡æ»¤ç­‰åŠŸèƒ½
"""

import numpy as np
import pandas as pd
from typing import Optional, Union, List, Tuple
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif
from sklearn.impute import SimpleImputer
import warnings


class pp:
    """
    æ•°æ®é¢„å¤„ç†ç±»ï¼Œæä¾›å„ç§é¢„å¤„ç†æ–¹æ³•
    """
    
    @staticmethod
    def process_survival_data(nadata, os_col: str = 'OS', os_time_col: str = 'OS.time', 
                              time_unit: str = 'auto'):
        """
        ç”Ÿå­˜æ•°æ®æ ‡å‡†å¤„ç†
        
        Parameters:
        -----------
        nadata : nadataå¯¹è±¡
            åŒ…å«ç”Ÿå­˜æ•°æ®çš„nadataå¯¹è±¡
        os_col : str
            ç”Ÿå­˜çŠ¶æ€åˆ—åï¼Œé»˜è®¤ä¸º'OS'
        os_time_col : str
            ç”Ÿå­˜æ—¶é—´åˆ—åï¼Œé»˜è®¤ä¸º'OS.time'
        time_unit : str
            æ—¶é—´å•ä½ï¼š'auto', 'days', 'months', 'years'
            å¦‚æœä¸º'auto'ï¼Œå°†è‡ªåŠ¨åˆ¤æ–­å¹¶ç»Ÿä¸€è½¬æ¢ä¸ºæœˆ
            
        Returns:
        --------
        nadata
            å¤„ç†åçš„nadataå¯¹è±¡
        """
        if nadata.Meta is None:
            raise ValueError("nadata.Meta is None, cannot process survival data")
        
        if os_col not in nadata.Meta.columns:
            raise ValueError(f"Column '{os_col}' not found in nadata.Meta")
        
        if os_time_col not in nadata.Meta.columns:
            raise ValueError(f"Column '{os_time_col}' not found in nadata.Meta")
        
        # æå–ç”Ÿå­˜æ•°æ®
        y = nadata.Meta.loc[:, [os_col, os_time_col]].copy()
        
        # å¤„ç†ç”Ÿå­˜æ—¶é—´å•ä½è½¬æ¢
        os_time = y[os_time_col]
        
        if time_unit == 'auto':
            # è‡ªåŠ¨åˆ¤æ–­æ—¶é—´å•ä½å¹¶ç»Ÿä¸€è½¬æ¢ä¸ºæœˆ
            max_time = os_time.max()
            if max_time > 1000:
                # å‡è®¾ä¸ºå¤©ï¼Œè½¬ä¸ºæœˆ
                y[os_time_col] = os_time / 30.44
                print(f"ğŸ• æ£€æµ‹åˆ°æ—¶é—´å•ä½ä¸ºå¤©ï¼Œå·²è½¬æ¢ä¸ºæœˆï¼ˆé™¤ä»¥30.44ï¼‰")
            elif max_time < 100:
                # å‡è®¾ä¸ºå¹´ï¼Œè½¬ä¸ºæœˆ
                y[os_time_col] = os_time * 12
                print(f"ğŸ• æ£€æµ‹åˆ°æ—¶é—´å•ä½ä¸ºå¹´ï¼Œå·²è½¬æ¢ä¸ºæœˆï¼ˆä¹˜ä»¥12ï¼‰")
            else:
                # å·²ä¸ºæœˆï¼Œæ— éœ€å¤„ç†
                print(f"ğŸ• æ£€æµ‹åˆ°æ—¶é—´å•ä½ä¸ºæœˆï¼Œæ— éœ€è½¬æ¢")
        elif time_unit == 'days':
            y[os_time_col] = os_time / 30.44
            print(f"ğŸ• å°†æ—¶é—´ä»å¤©è½¬æ¢ä¸ºæœˆï¼ˆé™¤ä»¥30.44ï¼‰")
        elif time_unit == 'years':
            y[os_time_col] = os_time * 12
            print(f"ğŸ• å°†æ—¶é—´ä»å¹´è½¬æ¢ä¸ºæœˆï¼ˆä¹˜ä»¥12ï¼‰")
        elif time_unit == 'months':
            # å·²ä¸ºæœˆï¼Œæ— éœ€å¤„ç†
            pass
        else:
            raise ValueError(f"Unsupported time_unit: {time_unit}")
        
        # å¤„ç†ç”Ÿå­˜çŠ¶æ€æ ‡ç­¾
        os_col_data = y[os_col]
        
        # åˆ¤æ–­OSæ˜¯å¦ä¸º0/1å˜é‡ï¼Œå¦‚æœä¸ºå­—ç¬¦ä¸²åˆ™è½¬æ¢
        if os_col_data.dtype == object or str(os_col_data.dtype).startswith('str'):
            # å¸¸è§ç”Ÿå­˜åˆ†ææ ‡ç­¾æ˜ å°„
            label_mapping = {
                'Dead': 1, 'Alive': 0,
                'deceased': 1, 'living': 0,
                '1': 1, '0': 0,
                'TRUE': 1, 'FALSE': 0,
                'True': 1, 'False': 0,
                'T': 1, 'F': 0,
                't': 1, 'f': 0
            }
            
            # å°è¯•æ˜ å°„
            y[os_col] = os_col_data.map(label_mapping)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœªæ˜ å°„çš„å€¼
            if y[os_col].isnull().any():
                try:
                    # å°è¯•ç›´æ¥è½¬ä¸ºint
                    y[os_col] = os_col_data.astype(int)
                    print(f"ğŸ·ï¸ å°†ç”Ÿå­˜çŠ¶æ€ä»å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•°å€¼")
                except Exception as e:
                    # æ˜¾ç¤ºæœªæ˜ å°„çš„å€¼
                    unmapped_values = os_col_data[y[os_col].isnull()].unique()
                    raise ValueError(f"OSåˆ—æ— æ³•è½¬æ¢ä¸º0/1å˜é‡ï¼Œæœªæ˜ å°„çš„å€¼: {unmapped_values}")
            else:
                print(f"ğŸ·ï¸ å°†ç”Ÿå­˜çŠ¶æ€ä»å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•°å€¼ï¼ˆæ˜ å°„æˆåŠŸï¼‰")
        else:
            # è‹¥å·²ä¸ºæ•°å€¼ï¼Œç¡®ä¿ä¸º0/1
            y[os_col] = os_col_data.apply(lambda v: 1 if v == 1 else 0)
            print(f"ğŸ·ï¸ ç”Ÿå­˜çŠ¶æ€å·²ä¸ºæ•°å€¼ï¼Œç¡®ä¿ä¸º0/1æ ¼å¼")
        
        # éªŒè¯å¤„ç†ç»“æœ
        unique_os_values = y[os_col].unique()
        if not all(val in [0, 1] for val in unique_os_values):
            raise ValueError(f"ç”Ÿå­˜çŠ¶æ€å¤„ç†å¤±è´¥ï¼ŒåŒ…å«é0/1å€¼: {unique_os_values}")
        
        # æ£€æŸ¥æ—¶é—´å€¼æ˜¯å¦åˆç†
        if (y[os_time_col] < 0).any():
            warnings.warn("æ£€æµ‹åˆ°è´Ÿçš„ç”Ÿå­˜æ—¶é—´å€¼")
        
        # å°†å¤„ç†åçš„æ•°æ®æ·»åŠ åˆ°nadata.Metaä¸­
        # åªå°†ç”Ÿå­˜çŠ¶æ€åˆ—èµ‹å€¼ç»™target_col
        nadata.Meta['Event'] = y[os_col]
    
        # æ›´æ–°åŸå§‹çš„ç”Ÿå­˜æ—¶é—´åˆ—
        nadata.Meta['Time'] = y[os_time_col]
        
        print(f"âœ… ç”Ÿå­˜æ•°æ®å¤„ç†å®Œæˆ")
        print(f"   - ç”Ÿå­˜çŠ¶æ€: {os_col} -> Event")
        print(f"   - ç”Ÿå­˜æ—¶é—´: '{os_time_col}'-> Time (å•ä½: æœˆ)")
        print(f"   - æ•°æ®å½¢çŠ¶: {nadata.Meta['Event'].shape}")
        print(f"   - ç”Ÿå­˜çŠ¶æ€åˆ†å¸ƒ: {nadata.Meta['Event'].value_counts().to_dict()}")
        return nadata
    
    @staticmethod
    def fillna(X, method: str = "mean", fill_value: float = 0):
        """
        å¤„ç†ç¼ºå¤±å€¼
        
        Parameters:
        -----------
        X : np.ndarray
            è¾“å…¥æ•°æ®çŸ©é˜µ
        method : str
            å¤„ç†æ–¹æ³•ï¼š'mean', 'median', 'zero', 'drop'
        fill_value : float
            å¡«å……å€¼ï¼Œç”¨äº'zero'æ–¹æ³•
            
        Returns:
        --------
        np.ndarray
            å¤„ç†åçš„æ•°æ®çŸ©é˜µ
        """
        if X is None:
            return X
        
        if not np.isnan(X).any():
            return X
        
        if method == "mean":
            # æ£€æŸ¥æ¯ä¸€åˆ—æ˜¯å¦å…¨ä¸ºNaNï¼Œè‹¥æ˜¯åˆ™ç”¨0å¡«å……ï¼Œå¦åˆ™ç”¨å‡å€¼å¡«å……
            nan_all_col = np.isnan(X).all(axis=0)
            if nan_all_col.any():
                X[:, nan_all_col] = 0
            # å¯¹å‰©ä½™æœ‰NaNçš„åˆ—ç”¨å‡å€¼å¡«å……
            imputer = SimpleImputer(strategy='mean')
            X = imputer.fit_transform(X)
            
        elif method == "median":
            # æ£€æŸ¥æ¯ä¸€åˆ—æ˜¯å¦å…¨ä¸ºNaNï¼Œè‹¥æ˜¯åˆ™ç”¨0å¡«å……ï¼Œå¦åˆ™ç”¨ä¸­ä½æ•°å¡«å……
            nan_all_col = np.isnan(X).all(axis=0)
            if nan_all_col.any():
                X[:, nan_all_col] = 0
            # å¯¹å‰©ä½™æœ‰NaNçš„åˆ—ç”¨ä¸­ä½æ•°å¡«å……
            imputer = SimpleImputer(strategy='median')
            X = imputer.fit_transform(X)
            
        elif method == "zero":
            # ç”¨æŒ‡å®šå€¼å¡«å……
            X = np.nan_to_num(X, nan=fill_value)
            
        elif method == "drop":
            # åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è¡Œ
            mask = ~np.isnan(X).any(axis=1)
            X = X[mask]
            
        else:
            raise ValueError(f"Unsupported fillna method: {method}")
        
        return X
    
    @staticmethod
    def scale(X, method: str = "standard"):
        """
        æ•°æ®æ ‡å‡†åŒ–
        
        Parameters:
        -----------
        X : np.ndarray
            è¾“å…¥æ•°æ®çŸ©é˜µ
        method : str
            æ ‡å‡†åŒ–æ–¹æ³•ï¼š'standard', 'minmax', 'robust'
            
        Returns:
        --------
        np.ndarray
            æ ‡å‡†åŒ–åçš„æ•°æ®çŸ©é˜µ
        """
        if X is None:
            return X
        
        if method == "standard":
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            
        elif method == "minmax":
            scaler = MinMaxScaler()
            X_scaled = scaler.fit_transform(X)
            
        elif method == "robust":
            scaler = RobustScaler()
            X_scaled = scaler.fit_transform(X)
            
        else:
            raise ValueError(f"Unsupported scale method: {method}")
        
        return X_scaled
    
    @staticmethod
    def x_train_test(X, nadata, test_size: float = 0.2, random_state: int = 42):
        """
        è·å–è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„Xæ•°æ®
        
        Parameters:
        -----------
        X : np.ndarray
            ç‰¹å¾æ•°æ®çŸ©é˜µ
        nadata : nadataå¯¹è±¡
            åŒ…å«åˆ’åˆ†ä¿¡æ¯çš„nadataå¯¹è±¡
        test_size : float
            æµ‹è¯•é›†æ¯”ä¾‹
        random_state : int
            éšæœºç§å­
            
        Returns:
        --------
        tuple
            (X_train, X_test)
        """
        if hasattr(nadata, 'Model') and hasattr(nadata.Model, 'indices'):
            # ä½¿ç”¨å·²ä¿å­˜çš„åˆ’åˆ†ä¿¡æ¯
            train_idx = nadata.Model.indices['train']
            test_idx = nadata.Model.indices['test']
            X_train, X_test = X[train_idx], X[test_idx]
        else:
            # ä½¿ç”¨éšæœºåˆ’åˆ†
            from sklearn.model_selection import train_test_split
            indices = np.arange(X.shape[0])
            train_idx, test_idx = train_test_split(
                indices, test_size=test_size, random_state=random_state
            )
            X_train, X_test = X[train_idx], X[test_idx]
        
        return X_train, X_test
    
    @staticmethod
    def y_train_test(y, nadata, test_size: float = 0.2, random_state: int = 42):
        """
        è·å–è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„yæ•°æ®
        
        Parameters:
        -----------
        y : pd.Series or np.ndarray
            æ ‡ç­¾æ•°æ®
        nadata : nadataå¯¹è±¡
            åŒ…å«åˆ’åˆ†ä¿¡æ¯çš„nadataå¯¹è±¡
        test_size : float
            æµ‹è¯•é›†æ¯”ä¾‹
        random_state : int
            éšæœºç§å­
            
        Returns:
        --------
        tuple
            (y_train, y_test)
        """
        if hasattr(nadata, 'Model') and hasattr(nadata.Model, 'indices'):
            # ä½¿ç”¨å·²ä¿å­˜çš„åˆ’åˆ†ä¿¡æ¯
            train_idx = nadata.Model.indices['train']
            test_idx = nadata.Model.indices['test']
            if isinstance(y, pd.Series):
                y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
            else:
                y_train, y_test = y[train_idx], y[test_idx]
        else:
            # ä½¿ç”¨éšæœºåˆ’åˆ†
            from sklearn.model_selection import train_test_split
            indices = np.arange(len(y))
            train_idx, test_idx = train_test_split(
                indices, test_size=test_size, random_state=random_state
            )
            if isinstance(y, pd.Series):
                y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
            else:
                y_train, y_test = y[train_idx], y[test_idx]
        
        return y_train, y_test

    @staticmethod
    def normalize(nadata, method: str = "zscore", scale_factor: float = 10000):
        """
        æ•°æ®æ ‡å‡†åŒ–
        
        Parameters:
        -----------
        nadata : nadataå¯¹è±¡
            åŒ…å«è¡¨è¾¾çŸ©é˜µçš„nadataå¯¹è±¡
        method : str
            æ ‡å‡†åŒ–æ–¹æ³•ï¼š'zscore', 'minmax', 'robust', 'quantile', 'cell_by_gene'
        scale_factor : float
            ç¼©æ”¾å› å­ï¼Œç”¨äºcell_by_geneæ–¹æ³•
            
        Returns:
        --------
        nadata
            æ ‡å‡†åŒ–åçš„nadataå¯¹è±¡
        """
        if nadata.X is None:
            raise ValueError("Expression matrix X is None")
        
        X = nadata.X.copy()
        
        if method == "zscore":
            scaler = StandardScaler()
            X_normalized = scaler.fit_transform(X.T).T
            
        elif method == "minmax":
            scaler = MinMaxScaler()
            X_normalized = scaler.fit_transform(X.T).T
            
        elif method == "robust":
            scaler = RobustScaler()
            X_normalized = scaler.fit_transform(X.T).T
            
        elif method == "quantile":
            # åˆ†ä½æ•°æ ‡å‡†åŒ–
            X_normalized = np.zeros_like(X)
            for i in range(X.shape[0]):
                gene_exp = X[i, :]
                q75, q25 = np.percentile(gene_exp, [75, 25])
                if q75 != q25:
                    X_normalized[i, :] = (gene_exp - q25) / (q75 - q25)
                else:
                    X_normalized[i, :] = gene_exp
                    
        elif method == "cell_by_gene":
            # æŒ‰ç»†èƒæ ‡å‡†åŒ–ï¼ˆå•ç»†èƒæ•°æ®å¸¸ç”¨ï¼‰
            X_normalized = _normalize_cell_by_gene(X, scale_factor)
            
        else:
            raise ValueError(f"Unsupported normalization method: {method}")
        
        nadata.X = X_normalized
        return nadata
    
    @staticmethod
    def handle_missing_values(nadata, method: str = "drop", fill_value: float = 0):
        """
        ç¼ºå¤±å€¼å¤„ç†
        
        Parameters:
        -----------
        nadata : nadataå¯¹è±¡
            åŒ…å«æ•°æ®çš„nadataå¯¹è±¡
        method : str
            å¤„ç†æ–¹æ³•ï¼š'drop', 'fill', 'interpolate'
        fill_value : float
            å¡«å……å€¼ï¼Œç”¨äºfillæ–¹æ³•
            
        Returns:
        --------
        nadata
            å¤„ç†åçš„nadataå¯¹è±¡
        """
        if nadata.X is None:
            return nadata
        
        X = nadata.X
        
        if method == "drop":
            # åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„åŸºå› æˆ–æ ·æœ¬
            # åˆ é™¤åŸºå› ï¼ˆè¡Œï¼‰
            gene_mask = ~np.isnan(X).any(axis=1)
            X_clean = X[gene_mask, :]
            if nadata.Var is not None:
                nadata.Var = nadata.Var.iloc[gene_mask]
            
            # åˆ é™¤æ ·æœ¬ï¼ˆåˆ—ï¼‰
            sample_mask = ~np.isnan(X_clean).any(axis=0)
            X_clean = X_clean[:, sample_mask]
            if nadata.Meta is not None:
                nadata.Meta = nadata.Meta.iloc[sample_mask]
            
            nadata.X = X_clean
            
        elif method == "fill":
            # ç”¨æŒ‡å®šå€¼å¡«å……
            X_filled = np.nan_to_num(X, nan=fill_value)
            nadata.X = X_filled
            
        elif method == "interpolate":
            # æ’å€¼å¡«å……
            from scipy.interpolate import interp1d
            
            X_interpolated = X.copy()
            for i in range(X.shape[0]):
                gene_exp = X[i, :]
                if np.isnan(gene_exp).any():
                    # æ‰¾åˆ°éç¼ºå¤±å€¼çš„ç´¢å¼•
                    valid_idx = ~np.isnan(gene_exp)
                    if valid_idx.sum() > 1:
                        # æ’å€¼
                        f = interp1d(np.where(valid_idx)[0], gene_exp[valid_idx], 
                                    kind='linear', fill_value='extrapolate')
                        all_idx = np.arange(len(gene_exp))
                        X_interpolated[i, :] = f(all_idx)
                    else:
                        # å¦‚æœåªæœ‰ä¸€ä¸ªæœ‰æ•ˆå€¼ï¼Œç”¨è¯¥å€¼å¡«å……
                        valid_value = gene_exp[valid_idx][0]
                        X_interpolated[i, :] = valid_value
            
            nadata.X = X_interpolated
            
        else:
            raise ValueError(f"Unsupported missing value method: {method}")
        
        return nadata
    
    @staticmethod
    def detect_outliers(nadata, method: str = "iqr", threshold: float = 1.5):
        """
        å¼‚å¸¸å€¼æ£€æµ‹
        
        Parameters:
        -----------
        nadata : nadataå¯¹è±¡
            åŒ…å«æ•°æ®çš„nadataå¯¹è±¡
        method : str
            æ£€æµ‹æ–¹æ³•ï¼š'iqr', 'zscore', 'isolation_forest'
        threshold : float
            é˜ˆå€¼
            
        Returns:
        --------
        nadata
            å¤„ç†åçš„nadataå¯¹è±¡
        """
        if nadata.X is None:
            return nadata
        
        X = nadata.X
        outlier_mask = np.zeros(X.shape, dtype=bool)
        
        if method == "iqr":
            # IQRæ–¹æ³•
            for i in range(X.shape[0]):
                gene_exp = X[i, :]
                Q1 = np.percentile(gene_exp, 25)
                Q3 = np.percentile(gene_exp, 75)
                IQR = Q3 - Q1
                lower_bound = Q1 - threshold * IQR
                upper_bound = Q3 + threshold * IQR
                outlier_mask[i, :] = (gene_exp < lower_bound) | (gene_exp > upper_bound)
                
        elif method == "zscore":
            # Z-scoreæ–¹æ³•
            for i in range(X.shape[0]):
                gene_exp = X[i, :]
                z_scores = np.abs((gene_exp - np.mean(gene_exp)) / np.std(gene_exp))
                outlier_mask[i, :] = z_scores > threshold
                
        elif method == "isolation_forest":
            # éš”ç¦»æ£®æ—æ–¹æ³•
            from sklearn.ensemble import IsolationForest
            
            iso_forest = IsolationForest(contamination=0.1, random_state=42)
            outlier_labels = iso_forest.fit_predict(X.T)
            outlier_mask = (outlier_labels == -1).reshape(X.shape[1], X.shape[0]).T
            
        else:
            raise ValueError(f"Unsupported outlier detection method: {method}")
        
        # å°†å¼‚å¸¸å€¼è®¾ä¸ºNaN
        X_clean = X.copy()
        X_clean[outlier_mask] = np.nan
        nadata.X = X_clean
        
        return nadata
    
    @staticmethod
    def filter_genes(nadata, method: str = "variance", **kwargs):
        """
        åŸºå› è¿‡æ»¤
        
        Parameters:
        -----------
        nadata : nadataå¯¹è±¡
            åŒ…å«æ•°æ®çš„nadataå¯¹è±¡
        method : str
            è¿‡æ»¤æ–¹æ³•ï¼š'variance', 'top_k', 'expression_threshold'
        **kwargs : 
            å…¶ä»–å‚æ•°
            
        Returns:
        --------
        nadata
            è¿‡æ»¤åçš„nadataå¯¹è±¡
        """
        if nadata.X is None:
            return nadata
        
        X = nadata.X
        
        if method == "variance":
            # æ–¹å·®è¿‡æ»¤
            threshold = kwargs.get('threshold', 0.01)
            selector = VarianceThreshold(threshold=threshold)
            X_filtered = selector.fit_transform(X.T).T
            gene_mask = selector.get_support()
            
        elif method == "top_k":
            # é€‰æ‹©å‰kä¸ªåŸºå› 
            k = kwargs.get('k', 1000)
            if k >= X.shape[0]:
                return nadata
            
            # è®¡ç®—æ–¹å·®
            variances = np.var(X, axis=1)
            top_indices = np.argsort(variances)[-k:]
            X_filtered = X[top_indices, :]
            gene_mask = np.zeros(X.shape[0], dtype=bool)
            gene_mask[top_indices] = True
            
        elif method == "expression_threshold":
            # è¡¨è¾¾é‡é˜ˆå€¼è¿‡æ»¤
            threshold = kwargs.get('threshold', 0)
            min_cells = kwargs.get('min_cells', 1)
            
            # è®¡ç®—æ¯ä¸ªåŸºå› åœ¨å¤šå°‘ä¸ªç»†èƒä¸­è¡¨è¾¾
            expressed_cells = (X > threshold).sum(axis=1)
            gene_mask = expressed_cells >= min_cells
            X_filtered = X[gene_mask, :]
            
        else:
            raise ValueError(f"Unsupported gene filtering method: {method}")
        
        nadata.X = X_filtered
        if nadata.Var is not None:
            nadata.Var = nadata.Var.iloc[gene_mask]
        if nadata.Prior is not None:
            nadata.Prior = nadata.Prior[:, gene_mask]
        
        return nadata
    
    @staticmethod
    def filter_samples(nadata, method: str = "quality", **kwargs):
        """
        æ ·æœ¬è¿‡æ»¤
        
        Parameters:
        -----------
        nadata : nadataå¯¹è±¡
            åŒ…å«æ•°æ®çš„nadataå¯¹è±¡
        method : str
            è¿‡æ»¤æ–¹æ³•ï¼š'quality', 'expression_threshold'
        **kwargs : 
            å…¶ä»–å‚æ•°
            
        Returns:
        --------
        nadata
            è¿‡æ»¤åçš„nadataå¯¹è±¡
        """
        if nadata.X is None:
            return nadata
        
        X = nadata.X
        
        if method == "quality":
            # è´¨é‡è¿‡æ»¤
            min_genes = kwargs.get('min_genes', 1)
            max_genes = kwargs.get('max_genes', float('inf'))
            
            # è®¡ç®—æ¯ä¸ªæ ·æœ¬è¡¨è¾¾çš„åŸºå› æ•°
            expressed_genes = (X > 0).sum(axis=0)
            sample_mask = (expressed_genes >= min_genes) & (expressed_genes <= max_genes)
            
        elif method == "expression_threshold":
            # è¡¨è¾¾é‡é˜ˆå€¼è¿‡æ»¤
            threshold = kwargs.get('threshold', 0)
            min_genes = kwargs.get('min_genes', 1)
            
            # è®¡ç®—æ¯ä¸ªæ ·æœ¬è¡¨è¾¾é‡è¶…è¿‡é˜ˆå€¼çš„åŸºå› æ•°
            expressed_genes = (X > threshold).sum(axis=0)
            sample_mask = expressed_genes >= min_genes
            
        else:
            raise ValueError(f"Unsupported sample filtering method: {method}")
        
        nadata.X = X[:, sample_mask]
        if nadata.Meta is not None:
            nadata.Meta = nadata.Meta.iloc[sample_mask]
        
        return nadata
    
    @staticmethod
    def split_data(nadata, test_size: float = 0.2,
                   random_state: int = 42, strategy: str = "random"):
        """
        æ•°æ®åˆ’åˆ†
        
        Parameters:
        -----------
        nadata : nadataå¯¹è±¡
            åŒ…å«æ•°æ®çš„nadataå¯¹è±¡
        test_size : float
            æµ‹è¯•é›†æ¯”ä¾‹
        val_size : float
            éªŒè¯é›†æ¯”ä¾‹
        random_state : int
            éšæœºç§å­
        strategy : str
            åˆ’åˆ†ç­–ç•¥ï¼š'random', 'stratified'
            
        Returns:
        --------
        nadata
            åŒ…å«åˆ’åˆ†ä¿¡æ¯çš„nadataå¯¹è±¡
        """
        if nadata.X is None:
            return nadata
        
        n_samples = nadata.X.shape[0]
        indices = np.arange(n_samples)
        
        if strategy == "random":
            from sklearn.model_selection import train_test_split
            
            # é¦–å…ˆåˆ’åˆ†å‡ºæµ‹è¯•é›†
            train_indices, test_indices = train_test_split(
                indices, test_size=test_size, random_state=random_state
            )

            
        elif strategy == "stratified":
            from sklearn.model_selection import train_test_split
            
            # éœ€è¦ç›®æ ‡å˜é‡è¿›è¡Œåˆ†å±‚æŠ½æ ·
            if nadata.Meta is not None and 'target' in nadata.Meta.columns:
                target = nadata.Meta['target']
                
                # é¦–å…ˆåˆ’åˆ†å‡ºæµ‹è¯•é›†
                train_indices, test_indices = train_test_split(
                    indices, test_size=test_size, random_state=random_state, 
                    stratify=target
                )

            else:
                warnings.warn("No target column found for stratified sampling, using random split")
                return pp.split_data(nadata, test_size, random_state, "random")
        
        # ä¿å­˜åˆ’åˆ†ä¿¡æ¯åˆ°nadata.Model.indicesä¸­
        nadata.Model.set_indices(
            train_idx=train_indices,
            test_idx=test_indices,
        )
        
        # åŒæ—¶ä¿å­˜ç­–ç•¥ä¿¡æ¯åˆ°configä¸­
        if not hasattr(nadata, 'config'):
            nadata.config = {}
        nadata.config['data_split_strategy'] = strategy
        
        return nadata


def _normalize_cell_by_gene(X: np.ndarray, scale_factor: float = 10000) -> np.ndarray:
    """
    æŒ‰ç»†èƒæ ‡å‡†åŒ–ï¼ˆå•ç»†èƒæ•°æ®å¸¸ç”¨ï¼‰
    
    Parameters:
    -----------
    X : np.ndarray
        è¡¨è¾¾çŸ©é˜µ
    scale_factor : float
        ç¼©æ”¾å› å­
        
    Returns:
    --------
    np.ndarray
        æ ‡å‡†åŒ–åçš„è¡¨è¾¾çŸ©é˜µ
    """
    # è®¡ç®—æ¯ä¸ªç»†èƒçš„æ€»è¡¨è¾¾é‡
    cell_sums = np.sum(X, axis=0)
    
    # æ ‡å‡†åŒ–
    X_normalized = X / cell_sums * scale_factor
    
    # å¯¹æ•°è½¬æ¢
    X_normalized = np.log1p(X_normalized)
    
    return X_normalized 