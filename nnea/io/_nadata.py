import torch
import pandas as pd
import numpy as np
from typing import Optional, Dict, Any, Union
import h5py
import pickle
import os
from datetime import datetime


class nadata(object):
    """
    NNEAçš„æ ¸å¿ƒæ•°æ®ç±»ï¼Œç”¨æ¥å‚¨å­˜æ•°æ®
    
    é‡æ„åçš„ç®€æ´æ•°æ®ç»“æ„è®¾è®¡ï¼š
    1. **è¡¨è¾¾çŸ©é˜µæ•°æ®ï¼ˆXï¼‰**: è¡Œæ˜¯åŸºå› æ•°ï¼Œåˆ—æ˜¯æ ·æœ¬æ•°ï¼Œæ”¯æŒç¨€ç–çŸ©é˜µæ ¼å¼
    2. **è¡¨å‹æ•°æ®ï¼ˆMetaï¼‰**: è¡Œæ˜¯æ ·æœ¬æ•°ï¼Œåˆ—æ˜¯æ ·æœ¬çš„ç‰¹å¾ï¼ŒåŒ…å«train/test/valç´¢å¼•
    3. **åŸºå› æ•°æ®ï¼ˆVarï¼‰**: è¡Œæ˜¯åŸºå› æ•°ï¼Œåˆ—æ˜¯åŸºå› ç‰¹å¾ï¼ŒåŒ…æ‹¬åŸºå› åç§°ã€ç±»å‹ã€é‡è¦æ€§ç­‰
    4. **å…ˆéªŒçŸ¥è¯†ï¼ˆPriorï¼‰**: åŸºå› é›†çš„0ï¼Œ1ç¨€ç–çŸ©é˜µï¼Œä»£è¡¨åŸºå› æ˜¯å¦åœ¨åŸºå› é›†åˆé‡Œ
    5. **æ¨¡å‹å®¹å™¨ï¼ˆModelï¼‰**: å‚¨å­˜æ‰€æœ‰æ¨¡å‹ã€é…ç½®ã€è®­ç»ƒå†å²ç­‰
    """

    def __init__(self, X=None, Meta=None, Var=None, Prior=None, uns=None):
        """
        åˆå§‹åŒ–nadataå¯¹è±¡
        
        Parameters:
        -----------
        X : Optional[Union[np.ndarray, torch.Tensor, pd.DataFrame]]
            è¡¨è¾¾çŸ©é˜µï¼Œå½¢çŠ¶ä¸º(åŸºå› æ•°, æ ·æœ¬æ•°)
        Meta : Optional[Union[np.ndarray, pd.DataFrame]]
            è¡¨å‹æ•°æ®ï¼Œå½¢çŠ¶ä¸º(æ ·æœ¬æ•°, ç‰¹å¾æ•°)ï¼ŒåŒ…å«train/test/valç´¢å¼•
        Var : Optional[Union[np.ndarray, pd.DataFrame]]
            åŸºå› æ•°æ®ï¼Œå½¢çŠ¶ä¸º(åŸºå› æ•°, ç‰¹å¾æ•°)
        Prior : Optional[Union[np.ndarray, torch.Tensor]]
            å…ˆéªŒçŸ¥è¯†çŸ©é˜µï¼Œå½¢çŠ¶ä¸º(åŸºå› é›†æ•°, åŸºå› æ•°)
        uns : Optional[Dict[str, Any]]
            å­˜å‚¨é¢å¤–ä¿¡æ¯çš„å­—å…¸ï¼Œå¦‚PCAæ•°æ®ã€æ•°æ®é›†ä¿¡æ¯ç­‰
        """
        # æ ¸å¿ƒæ•°æ®
        self.X = X          # è¡¨è¾¾çŸ©é˜µ
        self.Meta = Meta    # è¡¨å‹æ•°æ®ï¼ˆåŒ…å«ç´¢å¼•ï¼‰
        self.Var = Var      # åŸºå› æ•°æ®
        self.Prior = Prior  # å…ˆéªŒçŸ¥è¯†
        self.uns = uns if uns is not None else {}  # é¢å¤–ä¿¡æ¯å­—å…¸
        
        # æ¨¡å‹å®¹å™¨ - åŒ…å«æ‰€æœ‰æ¨¡å‹ç›¸å…³çš„å†…å®¹
        self.Model = ModelContainer(self)
        # è®¾ç½®ModelContainerå¯¹nadataçš„å¼•ç”¨
        self.Model._nadata = self

    def save(self, filepath: str, format: str = 'pt', save_data: bool = True):
        """
        ä¿å­˜nadataå¯¹è±¡
        
        Parameters:
        -----------
        filepath : str
            ä¿å­˜è·¯å¾„
        format : str
            ä¿å­˜æ ¼å¼ï¼Œæ”¯æŒ'pt', 'h5', 'pickle'
        save_data : bool
            æ˜¯å¦ä¿å­˜æ•°æ®ï¼Œå¦‚æœä¸ºFalseåªä¿å­˜æ¨¡å‹å’Œé…ç½®
        """
        if format == 'pt':
            # ä½¿ç”¨æ–°çš„ä¿å­˜å‡½æ•°
            from ._save import save_project
            save_project(self, filepath, save_data=save_data)
        elif format == 'h5':
            with h5py.File(filepath, 'w') as f:
                # ä¿å­˜è¡¨è¾¾çŸ©é˜µ
                if self.X is not None:
                    if isinstance(self.X, torch.Tensor):
                        f.create_dataset('X', data=self.X.cpu().numpy())
                    else:
                        f.create_dataset('X', data=self.X)
                
                # ä¿å­˜è¡¨å‹æ•°æ®
                if self.Meta is not None:
                    if isinstance(self.Meta, pd.DataFrame):
                        f.create_dataset('Meta', data=self.Meta.values)
                        f.attrs['Meta_columns'] = self.Meta.columns.tolist()
                    else:
                        f.create_dataset('Meta', data=self.Meta)
                
                # ä¿å­˜åŸºå› æ•°æ®
                if self.Var is not None:
                    if isinstance(self.Var, pd.DataFrame):
                        f.create_dataset('Var', data=self.Var.values)
                        f.attrs['Var_columns'] = self.Var.columns.tolist()
                    else:
                        f.create_dataset('Var', data=self.Var)
                
                # ä¿å­˜å…ˆéªŒçŸ¥è¯†
                if self.Prior is not None:
                    if isinstance(self.Prior, torch.Tensor):
                        f.create_dataset('Prior', data=self.Prior.cpu().numpy())
                    else:
                        f.create_dataset('Prior', data=self.Prior)
                
                # ä¿å­˜unså­—å…¸
                if hasattr(self, 'uns') and self.uns:
                    # å°†unså­—å…¸è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²å­˜å‚¨
                    import json
                    uns_json = json.dumps(self.uns, default=str)
                    f.attrs['uns'] = uns_json
                
                # ä¿å­˜æ¨¡å‹å®¹å™¨
                if self.Model:
                    f.attrs['Model'] = str(self.Model)
                
        elif format == 'pickle':
            with open(filepath, 'wb') as f:
                pickle.dump(self, f)
        else:
            raise ValueError(f"Unsupported format: {format}")

    def load(self, filepath: str):
        """
        åŠ è½½nadataå¯¹è±¡
        
        Parameters:
        -----------
        filepath : str
            æ–‡ä»¶è·¯å¾„
        """
        if filepath.endswith('.h5'):
            with h5py.File(filepath, 'r') as f:
                # åŠ è½½è¡¨è¾¾çŸ©é˜µ
                if 'X' in f:
                    self.X = f['X'][:]
                
                # åŠ è½½è¡¨å‹æ•°æ®
                if 'Meta' in f:
                    meta_data = f['Meta'][:]
                    if 'Meta_columns' in f.attrs:
                        meta_cols = f.attrs['Meta_columns']
                        self.Meta = pd.DataFrame(meta_data, columns=meta_cols)
                    else:
                        self.Meta = meta_data
                
                # åŠ è½½åŸºå› æ•°æ®
                if 'Var' in f:
                    var_data = f['Var'][:]
                    if 'Var_columns' in f.attrs:
                        var_cols = f.attrs['Var_columns']
                        self.Var = pd.DataFrame(var_data, columns=var_cols)
                    else:
                        self.Var = var_data
                
                # åŠ è½½å…ˆéªŒçŸ¥è¯†
                if 'Prior' in f:
                    self.Prior = f['Prior'][:]
                
                # åŠ è½½unså­—å…¸
                if 'uns' in f.attrs:
                    import json
                    uns_json = f.attrs['uns']
                    self.uns = json.loads(uns_json)
                else:
                    self.uns = {}
                
                # åŠ è½½æ¨¡å‹å®¹å™¨
                if 'Model' in f.attrs:
                    # è¿™é‡Œéœ€è¦å®ç°æ¨¡å‹å®¹å™¨çš„åŠ è½½é€»è¾‘
                    pass
                    
        elif filepath.endswith('.pkl'):
            with open(filepath, 'rb') as f:
                loaded_data = pickle.load(f)
                self.__dict__.update(loaded_data.__dict__)
        else:
            raise ValueError(f"Unsupported file format: {filepath}")

    def print(self, module: Optional[str] = None):
        """
        æ‰“å°ç±»çš„åŸºæœ¬ä¿¡æ¯ï¼Œæ”¯æŒæ‰“å°ç‰¹å®šæ¨¡å—
        
        Parameters:
        -----------
        module : Optional[str]
            è¦æ‰“å°çš„æ¨¡å—åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™æ‰“å°æ‰€æœ‰ä¿¡æ¯
        """
        if module is None:
            print("=== NNEA Data Object ===")
            print(f"Expression matrix (X): {self.X.shape if self.X is not None else 'None'}")
            print(f"Phenotype data (Meta): {self.Meta.shape if self.Meta is not None else 'None'}")
            print(f"Gene data (Var): {self.Var.shape if self.Var is not None else 'None'}")
            print(f"Prior knowledge (Prior): {self.Prior.shape if self.Prior is not None else 'None'}")
            print(f"Additional info (uns): {len(self.uns) if hasattr(self, 'uns') and self.uns else 0} keys")
            print(f"Model container: {self.Model}")
        elif module == 'X':
            print(f"Expression matrix shape: {self.X.shape if self.X is not None else 'None'}")
        elif module == 'Meta':
            print(f"Phenotype data shape: {self.Meta.shape if self.Meta is not None else 'None'}")
            if self.Meta is not None and hasattr(self.Meta, 'columns'):
                print(f"Meta columns: {list(self.Meta.columns)}")
        elif module == 'Var':
            print(f"Gene data shape: {self.Var.shape if self.Var is not None else 'None'}")
        elif module == 'Prior':
            print(f"Prior knowledge shape: {self.Prior.shape if self.Prior is not None else 'None'}")
        elif module == 'Model':
            print(f"Model container: {self.Model}")
        elif module == 'uns':
            print(f"Additional info (uns): {len(self.uns) if hasattr(self, 'uns') and self.uns else 0} keys")
            if hasattr(self, 'uns') and self.uns:
                for key, value in self.uns.items():
                    if isinstance(value, (list, np.ndarray)):
                        print(f"  {key}: {type(value).__name__} with shape {getattr(value, 'shape', len(value))}")
                    else:
                        print(f"  {key}: {value}")
        else:
            print(f"Unknown module: {module}")

    def copy(self):
        """
        æ·±æ‹·è´nadataå¯¹è±¡
        
        Returns:
        --------
        nadata
            æ‹·è´çš„nadataå¯¹è±¡
        """
        import copy
        return copy.deepcopy(self)

    def subset(self, samples: Optional[list] = None, genes: Optional[list] = None):
        """
        å­é›†é€‰æ‹©
        
        Parameters:
        -----------
        samples : Optional[list]
            æ ·æœ¬ç´¢å¼•åˆ—è¡¨
        genes : Optional[list]
            åŸºå› ç´¢å¼•åˆ—è¡¨
            
        Returns:
        --------
        nadata
            å­é›†nadataå¯¹è±¡
        """
        new_nadata = self.copy()
        
        if genes is not None:
            if self.X is not None:
                new_nadata.X = self.X[genes, :] if self.X is not None else None
            if self.Var is not None:
                new_nadata.Var = self.Var.iloc[genes] if isinstance(self.Var, pd.DataFrame) else self.Var[genes]
            if self.Prior is not None:
                new_nadata.Prior = self.Prior[:, genes]
        
        if samples is not None:
            if self.X is not None:
                new_nadata.X = self.X[:, samples] if self.X is not None else None
            if self.Meta is not None:
                new_nadata.Meta = self.Meta.iloc[samples] if isinstance(self.Meta, pd.DataFrame) else self.Meta[samples]
        
        return new_nadata

    def merge(self, other: 'nadata'):
        """
        åˆå¹¶ä¸¤ä¸ªnadataå¯¹è±¡
        
        Parameters:
        -----------
        other : nadata
            è¦åˆå¹¶çš„nadataå¯¹è±¡
        """
        # åˆå¹¶è¡¨è¾¾çŸ©é˜µ
        if self.X is not None and other.X is not None:
            self.X = np.concatenate([self.X, other.X], axis=1)
        
        # åˆå¹¶è¡¨å‹æ•°æ®
        if self.Meta is not None and other.Meta is not None:
            if isinstance(self.Meta, pd.DataFrame) and isinstance(other.Meta, pd.DataFrame):
                self.Meta = pd.concat([self.Meta, other.Meta], axis=0, ignore_index=True)
            else:
                self.Meta = np.concatenate([self.Meta, other.Meta], axis=0)
        
        # åˆå¹¶åŸºå› æ•°æ®
        if self.Var is not None and other.Var is not None:
            if isinstance(self.Var, pd.DataFrame) and isinstance(other.Var, pd.DataFrame):
                self.Var = pd.concat([self.Var, other.Var], axis=0, ignore_index=True)
            else:
                self.Var = np.concatenate([self.Var, other.Var], axis=0)
        
        # åˆå¹¶å…ˆéªŒçŸ¥è¯†
        if self.Prior is not None and other.Prior is not None:
            self.Prior = np.concatenate([self.Prior, other.Prior], axis=1)
        
        # åˆå¹¶unså­—å…¸
        if hasattr(self, 'uns') and hasattr(other, 'uns'):
            if self.uns is None:
                self.uns = {}
            if other.uns is not None:
                self.uns.update(other.uns)
        
        # åˆå¹¶æ¨¡å‹å®¹å™¨
        self.Model.merge(other.Model)

    def build(self):
        """
        æ„å»ºæ¨¡å‹ï¼Œæ¨¡å‹æ”¾å…¥nadataçš„Modelå®¹å™¨ä¸­
        """
        from ..model import build
        build(self)

    def train(self, verbose: int = 1):
        """
        è®­ç»ƒæ¨¡å‹ï¼Œæ”¯æŒverboseå‚æ•°
        
        Parameters:
        -----------
        verbose : int
            è¯¦ç»†ç¨‹åº¦ï¼š0-åªæ˜¾ç¤ºè¿›åº¦æ¡ï¼Œ1-æ˜¾ç¤ºè®­ç»ƒè¯¦æƒ…ï¼Œ2-æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        """
        from ..model import train
        train(self, verbose=verbose)

    def evaluate(self):
        """
        è¯„ä¼°æ¨¡å‹
        """
        from ..model import eval
        eval(self)

    def explain(self, verbose: int = 1):
        """
        æ¨¡å‹è§£é‡Šï¼Œæ”¯æŒverboseå‚æ•°
        
        Parameters:
        -----------
        verbose : int
            è¯¦ç»†ç¨‹åº¦ï¼š0-åªæ˜¾ç¤ºè¿›åº¦æ¡ï¼Œ1-æ˜¾ç¤ºè§£é‡Šè¯¦æƒ…ï¼Œ2-æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        """
        from ..model import explain
        explain(self, verbose=verbose)

    def compare_baseline_models(self, save_path="results", verbose: int = 1):
        """
        æ¯”è¾ƒåŸºçº¿æ¨¡å‹æ€§èƒ½
        
        Parameters:
        -----------
        save_path : str
            ç»“æœä¿å­˜è·¯å¾„
        verbose : int
            è¯¦ç»†ç¨‹åº¦ï¼š0-åªæ˜¾ç¤ºè¿›åº¦æ¡ï¼Œ1-æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯ï¼Œ2-æ˜¾ç¤ºè¯¦ç»†ç»“æœ
            
        Returns:
        --------
        dict
            æ¯”è¾ƒç»“æœæ‘˜è¦
        """
        import logging
        import os
        from sklearn.model_selection import train_test_split
        from sklearn.preprocessing import StandardScaler
        from sklearn.linear_model import LogisticRegression
        from sklearn.tree import DecisionTreeClassifier
        from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
        from sklearn.neural_network import MLPClassifier
        from sklearn.svm import SVC, LinearSVC
        from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score
        import matplotlib.pyplot as plt
        import pandas as pd
        import numpy as np
        
        logger = logging.getLogger(__name__)
        
        if verbose >= 1:
            logger.info("å¼€å§‹åŸºçº¿æ¨¡å‹æ¯”è¾ƒå®éªŒ...")
        
        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs(save_path, exist_ok=True)
        
        # è·å–æ•°æ®ç´¢å¼•
        train_indices = self.Model.get_indices('train')
        test_indices = self.Model.get_indices('test')
        
        if train_indices is None or test_indices is None:
            logger.warning("æ•°æ®ç´¢å¼•æœªè®¾ç½®ï¼Œå°†è‡ªåŠ¨åˆ†å‰²æ•°æ®...")
            # æ‰‹åŠ¨è®¾ç½®è®­ç»ƒå’Œæµ‹è¯•ç´¢å¼•
            n_samples = self.X.shape[1]  # æ ·æœ¬æ•°
            indices = list(range(n_samples))
            
            # è·å–é…ç½®ä¸­çš„åˆ†å‰²å‚æ•°
            config = self.Model.get_config()
            test_size = config.get('dataset', {}).get('test_size', 0.2)
            random_state = config.get('global', {}).get('seed', 42)
            
            # åˆ†å±‚æŠ½æ ·åˆ†å‰²æ•°æ®
            target_column = config.get('dataset', {}).get('target_column', 'class')
            y = self.Meta[target_column].values
            
            train_indices, test_indices = train_test_split(
                indices, 
                test_size=test_size, 
                stratify=y, 
                random_state=random_state
            )
            
            # è®¾ç½®ç´¢å¼•åˆ°Modelå®¹å™¨
            self.Model.set_indices(train_idx=train_indices, test_idx=test_indices)
        
        # ç¡®ä¿ç´¢å¼•æ˜¯æ•´æ•°ç±»å‹
        train_indices = [int(i) for i in train_indices]
        test_indices = [int(i) for i in test_indices]
        
        # è·å–ç›®æ ‡åˆ—å
        target_column = self.Model.get_config().get('dataset', {}).get('target_column', 'class')
        
        # è·å–è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
        X_train = self.X[:, train_indices].T  # è½¬ç½®ä¸º(æ ·æœ¬æ•°, ç‰¹å¾æ•°)
        X_test = self.X[:, test_indices].T    # è½¬ç½®ä¸º(æ ·æœ¬æ•°, ç‰¹å¾æ•°)
        y_train = self.Meta.iloc[train_indices][target_column].values
        y_test = self.Meta.iloc[test_indices][target_column].values
        
        if verbose >= 1:
            logger.info(f"è®­ç»ƒé›†å¤§å°: {X_train.shape}")
            logger.info(f"æµ‹è¯•é›†å¤§å°: {X_test.shape}")
            logger.info(f"ç±»åˆ«åˆ†å¸ƒ - è®­ç»ƒé›†: {np.bincount(y_train)}")
            logger.info(f"ç±»åˆ«åˆ†å¸ƒ - æµ‹è¯•é›†: {np.bincount(y_test)}")
        
        # æ•°æ®é¢„å¤„ç†
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # å®šä¹‰åŸºçº¿æ¨¡å‹
        models = {
            'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),
            'DecisionTree': DecisionTreeClassifier(random_state=42),
            'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),
            'AdaBoost': AdaBoostClassifier(random_state=42),
            'MLPClassifier': MLPClassifier(hidden_layer_sizes=(100,), random_state=42, max_iter=1000),
            'LinearSVM': LinearSVC(random_state=42, max_iter=1000),
            'RBFSVM': SVC(kernel='rbf', probability=True, random_state=42)
        }
        
        # è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹
        results = {}
        if verbose >= 1:
            logger.info("å¼€å§‹è®­ç»ƒå’Œè¯„ä¼°åŸºçº¿æ¨¡å‹...")
        
        for name, model in models.items():
            if verbose >= 1:
                logger.info(f"è®­ç»ƒ {name}...")
            
            try:
                # è®­ç»ƒæ¨¡å‹
                if name == 'LinearSVM':
                    # LinearSVCä¸æ”¯æŒæ¦‚ç‡é¢„æµ‹ï¼Œä½¿ç”¨SVCæ›¿ä»£
                    model = SVC(kernel='linear', probability=True, random_state=42)
                
                model.fit(X_train_scaled, y_train)
                
                # é¢„æµ‹
                y_pred = model.predict(X_test_scaled)
                y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None
                
                # è®¡ç®—æŒ‡æ ‡
                accuracy = accuracy_score(y_test, y_pred)
                f1 = f1_score(y_test, y_pred)
                precision = precision_score(y_test, y_pred)
                recall = recall_score(y_test, y_pred)
                auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else 0.0
                
                results[name] = {
                    'accuracy': accuracy,
                    'f1': f1,
                    'precision': precision,
                    'recall': recall,
                    'auc': auc,
                    'model': model
                }
                
                if verbose >= 1:
                    logger.info(f"  {name} - å‡†ç¡®ç‡: {accuracy:.4f}, AUC: {auc:.4f}")
                    
            except Exception as e:
                if verbose >= 1:
                    logger.warning(f"  {name} è®­ç»ƒå¤±è´¥: {e}")
                continue
        
        # ä¿å­˜ç»“æœåˆ°Modelå®¹å™¨
        self.Model.add_metadata('baseline_results', results)
        
        # åˆ›å»ºæ¯”è¾ƒå›¾
        if results:
            # åˆ›å»ºæ€§èƒ½æ¯”è¾ƒå›¾
            metrics = ['accuracy', 'f1', 'precision', 'recall', 'auc']
            fig, axes = plt.subplots(2, 3, figsize=(15, 10))
            axes = axes.flatten()
            
            for i, metric in enumerate(metrics):
                if i < len(axes):
                    values = [results[name][metric] for name in results.keys()]
                    names = list(results.keys())
                    
                    axes[i].bar(names, values)
                    axes[i].set_title(f'{metric.upper()} Comparison')
                    axes[i].set_ylabel(metric.upper())
                    axes[i].tick_params(axis='x', rotation=45)
            
            # éšè—å¤šä½™çš„å­å›¾
            for i in range(len(metrics), len(axes)):
                axes[i].set_visible(False)
            
            plt.tight_layout()
            plt.savefig(os.path.join(save_path, 'baseline_model_comparison.png'), dpi=300, bbox_inches='tight')
            plt.close()
            
            # åˆ›å»ºROCæ›²çº¿
            plt.figure(figsize=(10, 8))
            for name, result in results.items():
                if result['auc'] > 0:
                    y_pred_proba = result['model'].predict_proba(X_test_scaled)[:, 1]
                    from sklearn.metrics import roc_curve
                    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
                    plt.plot(fpr, tpr, label=f'{name} (AUC = {result["auc"]:.3f})')
            
            plt.plot([0, 1], [0, 1], 'k--', label='Random')
            plt.xlabel('False Positive Rate')
            plt.ylabel('True Positive Rate')
            plt.title('ROC Curves Comparison')
            plt.legend()
            plt.grid(True)
            plt.savefig(os.path.join(save_path, 'roc_curves.png'), dpi=300, bbox_inches='tight')
            plt.close()
            
            # ä¿å­˜ç»“æœè¡¨æ ¼
            results_df = pd.DataFrame([
                {
                    'Model': name,
                    'Accuracy': result['accuracy'],
                    'F1_Score': result['f1'],
                    'Precision': result['precision'],
                    'Recall': result['recall'],
                    'AUC': result['auc']
                }
                for name, result in results.items()
            ])
            
            results_df.to_csv(os.path.join(save_path, 'baseline_model_results.csv'), index=False)
            
            # è·å–æœ€ä½³æ¨¡å‹
            best_model_name = max(results.keys(), key=lambda x: results[x]['auc'])
            best_auc = results[best_model_name]['auc']
            
            if verbose >= 1:
                logger.info(f"æœ€ä½³åŸºçº¿æ¨¡å‹: {best_model_name}")
                logger.info(f"æœ€ä½³AUC: {best_auc:.4f}")
            
            # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
            with open(os.path.join(save_path, 'detailed_report.txt'), 'w', encoding='utf-8') as f:
                f.write("åŸºçº¿æ¨¡å‹æ¯”è¾ƒå®éªŒæŠ¥å‘Š\n")
                f.write("=" * 50 + "\n\n")
                f.write(f"æ•°æ®é›†å¤§å°: {X_train.shape[0]} è®­ç»ƒæ ·æœ¬, {X_test.shape[0]} æµ‹è¯•æ ·æœ¬\n")
                f.write(f"ç‰¹å¾æ•°é‡: {X_train.shape[1]}\n")
                f.write(f"ç±»åˆ«åˆ†å¸ƒ - è®­ç»ƒé›†: {np.bincount(y_train)}\n")
                f.write(f"ç±»åˆ«åˆ†å¸ƒ - æµ‹è¯•é›†: {np.bincount(y_test)}\n\n")
                
                f.write("æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ:\n")
                f.write("-" * 30 + "\n")
                for name, result in results.items():
                    f.write(f"{name}:\n")
                    f.write(f"  å‡†ç¡®ç‡: {result['accuracy']:.4f}\n")
                    f.write(f"  F1åˆ†æ•°: {result['f1']:.4f}\n")
                    f.write(f"  ç²¾ç¡®ç‡: {result['precision']:.4f}\n")
                    f.write(f"  å¬å›ç‡: {result['recall']:.4f}\n")
                    f.write(f"  AUC: {result['auc']:.4f}\n\n")
                
                f.write(f"æœ€ä½³æ¨¡å‹: {best_model_name}\n")
                f.write(f"æœ€ä½³AUC: {best_auc:.4f}\n")
            
            return {
                'best_model': best_model_name,
                'best_auc': best_auc,
                'results': results,
                'summary': results_df
            }
        
        else:
            logger.error("æ²¡æœ‰æˆåŠŸè®­ç»ƒçš„æ¨¡å‹")
            return None


class ModelContainer:
    """
    æ¨¡å‹å®¹å™¨ç±»ï¼Œç”¨äºç®¡ç†æ‰€æœ‰æ¨¡å‹ç›¸å…³çš„å†…å®¹
    åŒ…æ‹¬æ¨¡å‹ã€é…ç½®ã€è®­ç»ƒå†å²ã€æ•°æ®ç´¢å¼•ç­‰
    """
    
    def __init__(self, nadata_obj=None):
        """
        åˆå§‹åŒ–æ¨¡å‹å®¹å™¨
        
        Parameters:
        -----------
        nadata_obj : Optional[nadata]
            å…³è”çš„nadataå¯¹è±¡
        """
        # æ¨¡å‹å­—å…¸
        self.models = {}
        
        # é…ç½®ä¿¡æ¯
        self.config = {}
        
        # è®­ç»ƒå†å²
        self.train_results = {}
        
        # æ•°æ®ç´¢å¼•ï¼ˆtrain/test/valï¼‰
        self.indices = {
            'train': None,
            'test': None,
            'val': None
        }
        
        # å…¶ä»–å…ƒæ•°æ®
        self.metadata = {}
        
        # å…³è”çš„nadataå¯¹è±¡
        self._nadata = nadata_obj
    
    def add_model(self, name: str, model):
        """
        æ·»åŠ æ¨¡å‹
        
        Parameters:
        -----------
        name : str
            æ¨¡å‹åç§°
        model : Any
            æ¨¡å‹å¯¹è±¡
        """
        self.models[name] = model
    
    def get_model(self, name: str):
        """
        è·å–æ¨¡å‹
        
        Parameters:
        -----------
        name : str
            æ¨¡å‹åç§°
            
        Returns:
        --------
        Any
            æ¨¡å‹å¯¹è±¡
        """
        return self.models.get(name)
    
    def has_model(self, name: str) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æœ‰æŒ‡å®šæ¨¡å‹
        
        Parameters:
        -----------
        name : str
            æ¨¡å‹åç§°
            
        Returns:
        --------
        bool
            æ˜¯å¦å­˜åœ¨
        """
        return name in self.models
    
    def list_models(self) -> list:
        """
        åˆ—å‡ºæ‰€æœ‰æ¨¡å‹åç§°
        
        Returns:
        --------
        list
            æ¨¡å‹åç§°åˆ—è¡¨
        """
        return list(self.models.keys())
    
    def _print_config_details(self, config: dict, indent: str = ""):
        """
        é€’å½’æ‰“å°é…ç½®è¯¦ç»†ä¿¡æ¯
        
        Parameters:
        -----------
        config : dict
            é…ç½®å­—å…¸
        indent : str
            ç¼©è¿›å­—ç¬¦ä¸²
        """
        import logging
        logger = logging.getLogger(__name__)
        
        for key, value in config.items():
            if isinstance(value, dict):
                logger.info(f"{indent}ğŸ“ {key}:")
                self._print_config_details(value, indent + "  ")
            elif isinstance(value, list):
                logger.info(f"{indent}ğŸ“‹ {key}: {value}")
            elif isinstance(value, bool):
                status = "âœ…" if value else "âŒ"
                logger.info(f"{indent}{status} {key}: {value}")
            elif isinstance(value, (int, float)):
                logger.info(f"{indent}ğŸ”¢ {key}: {value}")
            else:
                logger.info(f"{indent}ğŸ“„ {key}: {value}")

    def set_config(self, config: dict):
        """
        è®¾ç½®é…ç½®
        
        Parameters:
        -----------
        config : dict
            é…ç½®å­—å…¸
        """
        self.config = config
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        import os
        outdir = config.get('global', {}).get('outdir', 'experiment/test')
        os.makedirs(outdir, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—è¾“å‡ºåˆ°æŒ‡å®šç›®å½•
        from ..logging_utils import setup_logging
        import logging
        
        # åˆ›å»ºæ—¥å¿—å­ç›®å½•
        log_dir = os.path.join(outdir, 'logs')
        os.makedirs(log_dir, exist_ok=True)
        
        # é‡æ–°é…ç½®æ—¥å¿—ï¼Œå°†æ—¥å¿—æ–‡ä»¶ä¿å­˜åˆ°outdir/logsç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = os.path.join(log_dir, f"experiment_{timestamp}.log")
        
        # é‡æ–°è®¾ç½®æ—¥å¿—é…ç½®
        setup_logging(log_file=log_file)
        
        # è®°å½•é…ç½®è®¾ç½®ä¿¡æ¯
        logger = logging.getLogger(__name__)
        logger.info(f"é…ç½®å·²è®¾ç½®ï¼Œè¾“å‡ºç›®å½•: {outdir}")
        logger.info(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
        
        # è¯¦ç»†æ‰“å°é…ç½®å‚æ•°
        logger.info("=" * 60)
        logger.info("ğŸ“‹ NNEAé…ç½®æ–‡ä»¶è¯¦ç»†å‚æ•°:")
        logger.info("=" * 60)
        self._print_config_details(config)
        logger.info("=" * 60)
        
        # å°†è¾“å‡ºç›®å½•ä¿¡æ¯å­˜å‚¨åˆ°é…ç½®ä¸­ï¼Œä¾›å…¶ä»–æ¨¡å—ä½¿ç”¨
        self.outdir = outdir
    
    def get_config(self) -> dict:
        """
        è·å–é…ç½®
        
        Returns:
        --------
        dict
            é…ç½®å­—å…¸
        """
        return self.config
    
    def set_train_results(self, results: dict):
        """
        è®¾ç½®è®­ç»ƒç»“æœ
        
        Parameters:
        -----------
        results : dict
            è®­ç»ƒç»“æœå­—å…¸
        """
        self.train_results = results
    
    def get_train_results(self) -> dict:
        """
        è·å–è®­ç»ƒç»“æœ
        
        Returns:
        --------
        dict
            è®­ç»ƒç»“æœå­—å…¸
        """
        return self.train_results
    
    def set_indices(self, train_idx=None, test_idx=None, val_idx=None):
        """
        è®¾ç½®æ•°æ®ç´¢å¼•åˆ°Modelå®¹å™¨çš„indicesä¸­
        
        Parameters:
        -----------
        train_idx : Optional[list]
            è®­ç»ƒé›†ç´¢å¼•
        test_idx : Optional[list]
            æµ‹è¯•é›†ç´¢å¼•
        val_idx : Optional[list]
            éªŒè¯é›†ç´¢å¼•
        """
        # ç›´æ¥å­˜å‚¨åˆ°Modelå®¹å™¨çš„indiceså±æ€§ä¸­
        if train_idx is not None:
            self.indices['train'] = train_idx
        if test_idx is not None:
            self.indices['test'] = test_idx
        if val_idx is not None:
            self.indices['val'] = val_idx
        else:
            # å¦‚æœval_idxä¸ºNoneï¼Œä»å­˜å‚¨ä¸­åˆ é™¤valç´¢å¼•
            self.indices['val'] = None
    
    def get_indices(self, split: str = None):
        """
        è·å–æ•°æ®ç´¢å¼•
        
        Parameters:
        -----------
        split : Optional[str]
            åˆ†å‰²ç±»å‹ï¼ˆ'train', 'test', 'val'ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›æ‰€æœ‰ç´¢å¼•
            
        Returns:
        --------
        Union[list, dict]
            ç´¢å¼•åˆ—è¡¨æˆ–å­—å…¸
        """
        # ç›´æ¥ä»Modelå®¹å™¨çš„indiceså±æ€§è·å–
        if split is None:
            return self.indices
        return self.indices.get(split)
    
    def get_var_indices(self, split: str = None):
        """
        ä»nadata.Varä¸­è·å–æ•°æ®ç´¢å¼•
        
        Parameters:
        -----------
        split : Optional[str]
            åˆ†å‰²ç±»å‹ï¼ˆ'train', 'test', 'val'ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›æ‰€æœ‰ç´¢å¼•
            
        Returns:
        --------
        Union[list, dict]
            ç´¢å¼•åˆ—è¡¨æˆ–å­—å…¸
        """
        if hasattr(self, '_nadata') and self._nadata is not None:
            try:
                import pandas as pd
                if self._nadata.Var is not None and 'indices' in self._nadata.Var.columns and len(self._nadata.Var) > 0:
                    indices_data = self._nadata.Var.loc[0, 'indices']
                    if split is None:
                        return indices_data
                    return indices_data.get(split) if isinstance(indices_data, dict) else None
            except ImportError:
                # å¦‚æœæ²¡æœ‰pandasï¼Œä»_indiceså±æ€§è·å–
                if hasattr(self._nadata, '_indices') and self._nadata._indices:
                    if split is None:
                        return self._nadata._indices
                    return self._nadata._indices.get(split)
        return None
    
    def add_metadata(self, key: str, value):
        """
        æ·»åŠ å…ƒæ•°æ®
        
        Parameters:
        -----------
        key : str
            é”®å
        value : Any
            å€¼
        """
        self.metadata[key] = value
    
    def get_metadata(self, key: str = None):
        """
        è·å–å…ƒæ•°æ®
        
        Parameters:
        -----------
        key : Optional[str]
            é”®åï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›æ‰€æœ‰å…ƒæ•°æ®
            
        Returns:
        --------
        Any
            å…ƒæ•°æ®å€¼æˆ–å­—å…¸
        """
        if key is None:
            return self.metadata
        return self.metadata.get(key)
    
    def merge(self, other: 'ModelContainer'):
        """
        åˆå¹¶å¦ä¸€ä¸ªæ¨¡å‹å®¹å™¨
        
        Parameters:
        -----------
        other : ModelContainer
            è¦åˆå¹¶çš„æ¨¡å‹å®¹å™¨
        """
        # åˆå¹¶æ¨¡å‹
        self.models.update(other.models)
        
        # åˆå¹¶é…ç½®ï¼ˆä»¥otherä¸ºå‡†ï¼‰
        if other.config:
            self.config = other.config
        
        # åˆå¹¶è®­ç»ƒç»“æœ
        if other.train_results:
            self.train_results.update(other.train_results)
        
        # åˆå¹¶ç´¢å¼•
        for key in ['train', 'test', 'val']:
            if other.indices[key] is not None:
                self.indices[key] = other.indices[key]
        
        # åˆå¹¶å…ƒæ•°æ®
        self.metadata.update(other.metadata)
    
    def __str__(self):
        """
        å­—ç¬¦ä¸²è¡¨ç¤º
        """
        return f"ModelContainer(models={list(self.models.keys())}, config_keys={list(self.config.keys())}, train_results_keys={list(self.train_results.keys())})"
    
    def __repr__(self):
        """
        è¯¦ç»†å­—ç¬¦ä¸²è¡¨ç¤º
        """
        return self.__str__()
    
    def __setitem__(self, key, value):
        """
        æ”¯æŒå­—å…¸èµ‹å€¼æ“ä½œï¼Œå°†å€¼å­˜å‚¨åˆ°modelså­—å…¸ä¸­
        
        Parameters:
        -----------
        key : str
            é”®å
        value : Any
            è¦å­˜å‚¨çš„å€¼
        """
        self.models[key] = value
    
    def __getitem__(self, key):
        """
        æ”¯æŒå­—å…¸è®¿é—®æ“ä½œï¼Œä»modelså­—å…¸ä¸­è·å–å€¼
        
        Parameters:
        -----------
        key : str
            é”®å
            
        Returns:
        --------
        Any
            å­˜å‚¨çš„å€¼
        """
        return self.models[key]
    
    def __contains__(self, key):
        """
        æ”¯æŒinæ“ä½œç¬¦ï¼Œæ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨äºmodelså­—å…¸ä¸­
        
        Parameters:
        -----------
        key : str
            é”®å
            
        Returns:
        --------
        bool
            æ˜¯å¦å­˜åœ¨
        """
        return key in self.models
    
    def get(self, key, default=None):
        """
        è·å–å€¼ï¼Œå¦‚æœé”®ä¸å­˜åœ¨åˆ™è¿”å›é»˜è®¤å€¼
        
        Parameters:
        -----------
        key : str
            é”®å
        default : Any
            é»˜è®¤å€¼
            
        Returns:
        --------
        Any
            å­˜å‚¨çš„å€¼æˆ–é»˜è®¤å€¼
        """
        return self.models.get(key, default)