"""
NNEAæ¨¡å‹å·¥å‚
æ ¹æ®é…ç½®é€‰æ‹©ä¸åŒçš„æ¨¡å‹ç±»å‹
"""

import logging
import torch
import os
from typing import Dict, Any, Optional
from .base import BaseModel
from .nnea_classifier import NNEAClassifier
from .nnea_survival import NNEASurvival
from ..utils.helpers import ensure_reproducibility
import torch.nn as nn
import numpy as np
from .nnea_autoencoder import NNEAAutoencoder
from .nnea_regresser import NNEARegresser
from .nnea_umap import NNEAUMAP

logger = logging.getLogger(__name__)

def build_model(config: Dict[str, Any]) -> BaseModel:
    """
    æ ¹æ®é…ç½®æ„å»ºæ¨¡å‹
    
    Args:
        config: æ¨¡å‹é…ç½®
        
    Returns:
        æ„å»ºå¥½çš„æ¨¡å‹å®ä¾‹
    """
    # ç¡®ä¿å®éªŒå¯é‡å¤æ€§
    ensure_reproducibility(config)
    
    model_type = config.get('global', {}).get('model', 'nnea')
    
    # ç¡®ä¿è®¾å¤‡é…ç½®æ­£ç¡®ä¼ é€’
    device_config = config.get('global', {}).get('device', 'cpu')
    if device_config == 'cuda' and torch.cuda.is_available():
        config['device'] = 'cuda'
    else:
        config['device'] = 'cpu'
    
    # å¤„ç†NNEAé…ç½®çš„å±•å¹³
    if model_type == 'nnea' and 'nnea' in config:
        # å±•å¹³NNEAé…ç½®
        # ç›´æ¥ä½¿ç”¨åµŒå¥—é…ç½®ç»“æ„ï¼Œä¸è¿›è¡Œflatten
        model_config = config
    else:
        model_config = config
    
    if model_type == 'nnea':
        logger.info("æ„å»ºNNEAåˆ†ç±»å™¨")
        return NNEAClassifier(model_config)
    elif model_type == 'nnea_regression':
        logger.info("æ„å»ºNNEAå›å½’å™¨")
        return NNEARegresser(model_config)
    elif model_type == 'nnea_survival':
        logger.info("æ„å»ºNNEAç”Ÿå­˜åˆ†ææ¨¡å‹")
        return NNEASurvival(model_config)
    elif model_type == 'nnea_autoencoder':
        logger.info("æ„å»ºNNEAè‡ªç¼–ç å™¨")
        return NNEAAutoencoder(model_config)
    elif model_type == 'nnea_umap':
        logger.info("æ„å»ºNNEA UMAPæ¨¡å‹")
        return NNEAUMAP(model_config)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")

def build(nadata) -> None:
    """
    æ„å»ºæ¨¡å‹å¹¶æ·»åŠ åˆ°nadataçš„Modelå®¹å™¨ä¸­
    
    Args:
        nadata: nadataå¯¹è±¡
    """
    if nadata is None:
        raise ValueError("nadataå¯¹è±¡ä¸èƒ½ä¸ºç©º")
    
    # è·å–æ¨¡å‹é…ç½®
    config = nadata.Model.get_config()
    if not config:
        # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œå°è¯•ä»nadata.configè·å–ï¼ˆå‘åå…¼å®¹ï¼‰
        config = getattr(nadata, 'config', {})
        if config:
            nadata.Model.set_config(config)
    
    model_type = config.get('global', {}).get('model', 'nnea')
    
    # æ„å»ºæ¨¡å‹
    model = build_model(config)
    
    # æ„å»ºæ¨¡å‹
    model.build(nadata)
    
    # æ‰“å°æ¨¡å‹ç»“æ„ä¿¡æ¯
    if model_type == 'nnea' and hasattr(model, 'model'):
        print_model_structure(model.model)
    
    # ä¿å­˜åˆ°nadataçš„Modelå®¹å™¨
    nadata.Model.add_model(model_type, model)
    
    logger.info(f"æ¨¡å‹å·²æ„å»ºå¹¶æ·»åŠ åˆ°nadata.Model: {model_type}")

def print_model_structure(model):
    """
    æ‰“å°NNEAæ¨¡å‹çš„ç»“æ„ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯geneset_layerå’Œfocus_layer
    
    Args:
        model: NNEAModelå®ä¾‹
    """
    print("\n" + "="*60)
    print("ğŸ” NNEAæ¨¡å‹ç»“æ„åˆ†æ")
    print("="*60)
    
    # æ‰“å°geneset_layerç»“æ„
    if hasattr(model, 'geneset_layer'):
        print("\nğŸ“Š Geneset Layer ç»“æ„:")
        print("-" * 40)
        geneset_layer = model.geneset_layer
        print(f"ç±»å‹: {type(geneset_layer).__name__}")
        print(f"åŸºå› æ•°é‡: {geneset_layer.num_genes}")
        print(f"åŸºå› é›†æ•°é‡: {geneset_layer.num_sets}")
        print(f"æœ€å°åŸºå› é›†å¤§å°: {geneset_layer.min_set_size}")
        print(f"æœ€å¤§åŸºå› é›†å¤§å°: {geneset_layer.max_set_size}")
        print(f"å…ˆéªŒçŸ¥è¯†: {'æ˜¯' if geneset_layer.piror_knowledge is not None else 'å¦'}")
        print(f"å†»ç»“å…ˆéªŒ: {geneset_layer.freeze_piror}")
        print(f"Dropoutç‡: {geneset_layer.geneset_dropout.p}")
        
        # æ‰“å°åŸºå› é›†æˆå‘˜å…³ç³»çŸ©é˜µçš„å½¢çŠ¶
        if hasattr(geneset_layer, 'set_membership'):
            membership_shape = geneset_layer.set_membership.shape
            print(f"åŸºå› é›†æˆå‘˜å…³ç³»çŸ©é˜µå½¢çŠ¶: {membership_shape}")
            
            # è®¡ç®—ç¨€ç–æ€§
            membership = geneset_layer.set_membership.detach()
            sparsity = (membership == 0).float().mean().item()
            print(f"æˆå‘˜å…³ç³»çŸ©é˜µç¨€ç–æ€§: {sparsity:.3f}")
    
    # æ‰“å°focus_layerç»“æ„
    if hasattr(model, 'focus_layer'):
        print("\nğŸ¯ Focus Layer ç»“æ„:")
        print("-" * 40)
        focus_layer = model.focus_layer
        print(f"ç±»å‹: {type(focus_layer).__name__}")
        
        # åˆ†æfocus_layerçš„ç»„æˆ
        if isinstance(focus_layer, nn.Sequential):
            print(f"å±‚æ•°: {len(focus_layer)}")
            for i, layer in enumerate(focus_layer):
                print(f"  å±‚ {i+1}: {type(layer).__name__}")
                if hasattr(layer, 'in_features') and hasattr(layer, 'out_features'):
                    print(f"    è¾“å…¥ç»´åº¦: {layer.in_features}")
                    print(f"    è¾“å‡ºç»´åº¦: {layer.out_features}")
        else:
            print(f"å±‚ç»“æ„: {focus_layer}")
    
    # æ‰“å°ç”Ÿç‰©å­¦çº¦æŸå±‚
    if hasattr(model, 'bio_constraint_layer') and model.bio_constraint_layer is not None:
        print("\nğŸ§¬ Biological Constraint Layer:")
        print("-" * 40)
        bio_layer = model.bio_constraint_layer
        print(f"ç±»å‹: {type(bio_layer).__name__}")
        print(f"è¾“å…¥ç»´åº¦: {bio_layer.input_dim}")
        print(f"å…ˆéªŒçŸ¥è¯†å½¢çŠ¶: {bio_layer.piror_knowledge.shape}")
    
    # æ‰“å°æ¨¡å‹æ€»ä½“ä¿¡æ¯
    print("\nğŸ“ˆ æ¨¡å‹æ€»ä½“ä¿¡æ¯:")
    print("-" * 40)
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {trainable_params:,}")
    print(f"è®¾å¤‡: {next(model.parameters()).device}")
    
    print("\n" + "="*60)

def train(nadata, model_name: Optional[str] = None, verbose: int = 1) -> Dict[str, Any]:
    """
    è®­ç»ƒæ¨¡å‹
    
    Args:
        nadata: nadataå¯¹è±¡
        model_name: æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹
        verbose: è¯¦ç»†ç¨‹åº¦ï¼Œ0=åªæ˜¾ç¤ºè¿›åº¦æ¡ï¼Œ1=æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯ï¼Œ2=æ˜¾ç¤ºè¯¦ç»†è¯„ä¼°ç»“æœ
        
    Returns:
        è®­ç»ƒç»“æœ
    """
    if not nadata.Model.models:
        raise ValueError("nadata.Modelä¸­æ²¡æœ‰æ¨¡å‹ï¼Œè¯·å…ˆè°ƒç”¨build()")
    
    # ç¡®å®šè¦è®­ç»ƒçš„æ¨¡å‹
    if model_name is None:
        model_type = nadata.Model.get_config().get('global', {}).get('model', 'nnea')
        model = nadata.Model.get_model(model_type)
    else:
        model = nadata.Model.get_model(model_name)
    
    if model is None:
        raise ValueError(f"æœªæ‰¾åˆ°æ¨¡å‹: {model_name or 'default'}")
    
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨tailorç­–ç•¥
    config = nadata.Model.get_config()
    training_config = config.get('training', {})
    tailor_enabled = training_config.get('tailor', False)
    
    if tailor_enabled:
        # ä½¿ç”¨tailorè®­ç»ƒç­–ç•¥
        train_results = _train_with_tailor(nadata, model, verbose=verbose)
    else:
        # ä½¿ç”¨æ ‡å‡†è®­ç»ƒç­–ç•¥
        train_results = model.train(nadata, verbose=verbose)
    
    # ä¿å­˜è®­ç»ƒç»“æœåˆ°Modelå®¹å™¨
    nadata.Model.set_train_results(train_results)
    
    return train_results

def _train_with_tailor(nadata, model, verbose: int = 1) -> Dict[str, Any]:
    """
    ä½¿ç”¨å¾ªç¯tailorç­–ç•¥è®­ç»ƒæ¨¡å‹ï¼Œæ¯è¿‡tailor_epochä¸ªepochéƒ½è¿›è¡Œæ¨¡å‹è£å‰ª
    æ·»åŠ æ—©åœæœºåˆ¶ï¼šå¦‚æœè¿ç»­3æ¬¡tailoråéªŒè¯æŸå¤±æ²¡æœ‰ä¸‹é™ï¼Œåˆ™åœæ­¢è®­ç»ƒ
    
    Args:
        nadata: nadataå¯¹è±¡
        model: æ¨¡å‹å®ä¾‹
        verbose: è¯¦ç»†ç¨‹åº¦
        
    Returns:
        è®­ç»ƒç»“æœ
    """
    config = nadata.Model.get_config()
    training_config = config.get('training', {})
    
    # è·å–tailorç›¸å…³å‚æ•°
    tailor_epoch = training_config.get('tailor_epoch', 20)
    tailor_geneset = training_config.get('tailor_geneset', 2)
    total_epochs = training_config.get('epochs', 100)
    
    # è·å–è¾“å‡ºç›®å½•ï¼ˆå·²åœ¨set_configä¸­åˆ›å»ºï¼‰
    outdir = config.get('global', {}).get('outdir', 'experiment/test')
    
    logger = logging.getLogger(__name__)
    logger.info(f"å¯ç”¨å¾ªç¯tailorç­–ç•¥: tailor_epoch={tailor_epoch}, tailor_geneset={tailor_geneset}, total_epochs={total_epochs}")
    logger.info(f"è¾“å‡ºç›®å½•: {outdir}")
    
    # åˆå§‹åŒ–å˜é‡
    current_model = model
    current_epoch = 0
    stage_results = []
    tailor_history = []
    model_type = config.get('global', {}).get('model', 'nnea')
    
    # æ—©åœæœºåˆ¶å˜é‡
    best_val_loss = float('inf')
    best_model_state = None
    best_stage = 0
    no_improvement_count = 0
    max_no_improvement = 3  # è¿ç»­3æ¬¡tailoråéªŒè¯æŸå¤±æ²¡æœ‰ä¸‹é™åˆ™åœæ­¢
    
    # å¾ªç¯è®­ç»ƒå’Œè£å‰ª
    while current_epoch < total_epochs:
        # è®¡ç®—å½“å‰é˜¶æ®µçš„è®­ç»ƒè½®æ•°
        if current_epoch + tailor_epoch <= total_epochs:
            epochs_to_train = tailor_epoch
        else:
            epochs_to_train = total_epochs - current_epoch
        
        stage_num = len(stage_results) + 1
        logger.info(f"ç¬¬{stage_num}é˜¶æ®µè®­ç»ƒ: ä»ç¬¬{current_epoch}ä¸ªepochè®­ç»ƒåˆ°ç¬¬{current_epoch + epochs_to_train}ä¸ªepoch")
        
        # è®­ç»ƒå½“å‰é˜¶æ®µ
        stage_result = current_model.train(nadata, verbose=verbose, max_epochs=epochs_to_train, continue_training=(current_epoch > 0))
        stage_results.append(stage_result)
        
        current_epoch += epochs_to_train
        
        # è·å–å½“å‰é˜¶æ®µçš„éªŒè¯æŸå¤±
        current_val_loss = stage_result.get('final_val_loss', float('inf'))
        if current_val_loss is None:
            current_val_loss = float('inf')
        
        logger.info(f"ç¬¬{stage_num}é˜¶æ®µéªŒè¯æŸå¤±: {current_val_loss:.6f}")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
        if current_val_loss < best_val_loss:
            best_val_loss = current_val_loss
            best_stage = stage_num
            no_improvement_count = 0
            # ä¿å­˜æœ€ä½³æ¨¡å‹çŠ¶æ€
            best_model_state = current_model.model.state_dict().copy()
            logger.info(f"âœ… ç¬¬{stage_num}é˜¶æ®µéªŒè¯æŸå¤±æ”¹å–„åˆ° {best_val_loss:.6f}")
        else:
            no_improvement_count += 1
            logger.info(f"âš ï¸ ç¬¬{stage_num}é˜¶æ®µéªŒè¯æŸå¤±æœªæ”¹å–„ï¼Œè¿ç»­æœªæ”¹å–„æ¬¡æ•°: {no_improvement_count}/{max_no_improvement}")
        
        # ä¿å­˜å½“å‰é˜¶æ®µçš„ç»“æœ
        stage_info = {
            'stage': stage_num,
            'epoch': current_epoch,
            'val_loss': current_val_loss,
            'best_val_loss': best_val_loss,
            'no_improvement_count': no_improvement_count
        }
        tailor_history.append(stage_info)
        
        logger.info(f"ğŸ“Š ç¬¬{stage_num}é˜¶æ®µè®­ç»ƒå®Œæˆï¼ŒéªŒè¯æŸå¤±: {current_val_loss:.6f}")
        
        # æ£€æŸ¥æ—©åœæ¡ä»¶
        if no_improvement_count >= max_no_improvement:
            logger.info(f"ğŸ›‘ è¿ç»­{max_no_improvement}æ¬¡tailoråéªŒè¯æŸå¤±æœªæ”¹å–„ï¼Œè§¦å‘æ—©åœï¼")
            logger.info(f"   æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f} (ç¬¬{best_stage}é˜¶æ®µ)")
            break
        
        # å¦‚æœè¿˜æ²¡åˆ°æ€»è½®æ•°ï¼Œè¿›è¡Œè£å‰ª
        if current_epoch < total_epochs:
            logger.info(f"ç¬¬{stage_num}é˜¶æ®µè®­ç»ƒå®Œæˆï¼Œå¼€å§‹è£å‰ªæ¨¡å‹...")
            
            # è·å–åŸºå› é›†é‡è¦æ€§
            logger.info("è®¡ç®—åŸºå› é›†é‡è¦æ€§...")
            try:
                explain_results = current_model.explain(nadata, method='importance')
                geneset_importance = np.array(explain_results['importance']['geneset_importance'])
                logger.info(f"åŸºå› é›†é‡è¦æ€§è®¡ç®—å®Œæˆï¼Œå½¢çŠ¶: {geneset_importance.shape}")
            except Exception as e:
                logger.error(f"åŸºå› é›†é‡è¦æ€§è®¡ç®—å¤±è´¥: {e}")
                # ä½¿ç”¨éšæœºé‡è¦æ€§ä½œä¸ºå¤‡é€‰
                geneset_importance = np.random.rand(current_model.model.num_genesets)
            
            # ç¡®å®šè¦ç§»é™¤çš„åŸºå› é›†ï¼ˆæœ€ä¸é‡è¦çš„ï¼‰
            num_genesets_to_remove = tailor_geneset
            if num_genesets_to_remove >= len(geneset_importance):
                logger.warning(f"è¦ç§»é™¤çš„åŸºå› é›†æ•°é‡({num_genesets_to_remove})å¤§äºç­‰äºæ€»åŸºå› é›†æ•°é‡({len(geneset_importance)})ï¼Œè°ƒæ•´ä¸ºç§»é™¤1ä¸ª")
                num_genesets_to_remove = 1
            
            # æ‰¾åˆ°æœ€ä¸é‡è¦çš„åŸºå› é›†ç´¢å¼•
            least_important_indices = np.argsort(geneset_importance)[:num_genesets_to_remove]
            important_indices = np.argsort(geneset_importance)[num_genesets_to_remove:]
            
            # å°è¯•è·å–genesets_annotatedçš„key
            genesets_annotated = nadata.uns.get('nnea_explain', {}).get('importance', {}).get('genesets', {})
            if genesets_annotated:
                # è·å–genesets_annotatedçš„keyåˆ—è¡¨
                geneset_keys = list(genesets_annotated.keys())
                
                # å°†ç´¢å¼•æ˜ å°„åˆ°geneset key
                removed_keys = [geneset_keys[idx] if idx < len(geneset_keys) else f"Geneset_{idx}" for idx in least_important_indices]
                kept_keys = [geneset_keys[idx] if idx < len(geneset_keys) else f"Geneset_{idx}" for idx in important_indices]
                
                logger.info(f"å°†ç§»é™¤åŸºå› é›†: {removed_keys}")
                logger.info(f"ä¿ç•™åŸºå› é›†: {kept_keys}")
            else:
                logger.info(f"å°†ç§»é™¤åŸºå› é›†ç´¢å¼•: {least_important_indices.tolist()}")
                logger.info(f"ä¿ç•™åŸºå› é›†ç´¢å¼•: {important_indices.tolist()}")
            
            # è®°å½•è£å‰ªä¿¡æ¯
            tailor_info = {
                'stage': stage_num,
                'epoch': current_epoch,
                'removed_genesets': least_important_indices.tolist(),
                'kept_genesets': important_indices.tolist(),
                'geneset_importance': geneset_importance.tolist(),
                'num_genesets_before': len(geneset_importance),
                'num_genesets_after': len(important_indices),
                'val_loss': current_val_loss,
                'no_improvement_count': no_improvement_count
            }
            
            # å¦‚æœæœ‰genesets_annotatedï¼Œæ·»åŠ keyä¿¡æ¯
            if genesets_annotated:
                geneset_keys = list(genesets_annotated.keys())
                removed_keys = [geneset_keys[idx] if idx < len(geneset_keys) else f"Geneset_{idx}" for idx in least_important_indices]
                kept_keys = [geneset_keys[idx] if idx < len(geneset_keys) else f"Geneset_{idx}" for idx in important_indices]
                tailor_info['removed_geneset_keys'] = removed_keys
                tailor_info['kept_geneset_keys'] = kept_keys
            tailor_history.append(tailor_info)
            
            # è£å‰ªæ¨¡å‹
            logger.info("å¼€å§‹è£å‰ªæ¨¡å‹...")
            cropped_model = _crop_nnea_model(nadata, current_model, important_indices, config)
            
            # æ›´æ–°nadataä¸­çš„æ¨¡å‹
            nadata.Model.add_model(f"{model_type}_cropped_stage_{stage_num}", cropped_model)
            
            # æ›´æ–°å½“å‰æ¨¡å‹ä¸ºè£å‰ªåçš„æ¨¡å‹
            current_model = cropped_model
            
            logger.info(f"ç¬¬{stage_num}é˜¶æ®µè£å‰ªå®Œæˆï¼Œå‰©ä½™åŸºå› é›†æ•°é‡: {len(important_indices)}")
        else:
            logger.info("è®­ç»ƒå®Œæˆï¼Œæ— éœ€è¿›ä¸€æ­¥è£å‰ª")
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    if best_model_state is not None:
        logger.info(f"ğŸ”„ åŠ è½½æœ€ä½³æ¨¡å‹ (ç¬¬{best_stage}é˜¶æ®µï¼ŒéªŒè¯æŸå¤±: {best_val_loss:.6f})")
        
        # æ£€æŸ¥å½“å‰æ¨¡å‹ä¸æœ€ä½³æ¨¡å‹çŠ¶æ€çš„å‚æ•°ç»´åº¦æ˜¯å¦åŒ¹é…
        current_state_dict = current_model.model.state_dict()
        best_state_dict = best_model_state
        
        # æ£€æŸ¥å…³é”®å‚æ•°ç»´åº¦æ˜¯å¦åŒ¹é…
        dimension_mismatch = False
        mismatch_info = []
        
        for key in best_state_dict.keys():
            if key in current_state_dict:
                if best_state_dict[key].shape != current_state_dict[key].shape:
                    dimension_mismatch = True
                    mismatch_info.append(f"{key}: {best_state_dict[key].shape} vs {current_state_dict[key].shape}")
        
        if dimension_mismatch:
            logger.warning(f"âš ï¸ æ£€æµ‹åˆ°å‚æ•°ç»´åº¦ä¸åŒ¹é…ï¼Œè¿™å¯èƒ½æ˜¯ç”±äºæ¨¡å‹è£å‰ªå¯¼è‡´çš„:")
            for info in mismatch_info:
                logger.warning(f"   {info}")
            
            # å°è¯•ä»æœ€ä½³æ¨¡å‹çŠ¶æ€é‡å»ºæ¨¡å‹
            logger.info("ğŸ”„ å°è¯•ä»æœ€ä½³æ¨¡å‹çŠ¶æ€é‡å»ºæ¨¡å‹...")
            try:
                # ä»æœ€ä½³æ¨¡å‹çŠ¶æ€æ¨æ–­åŸå§‹é…ç½®
                best_num_genesets = best_state_dict.get('geneset_layer.query_vectors', torch.tensor([])).shape[0]
                if best_num_genesets > 0:
                    # åˆ›å»ºä¸æœ€ä½³æ¨¡å‹çŠ¶æ€åŒ¹é…çš„é…ç½®
                    best_config = config.copy()
                    nnea_config = best_config.get('nnea', {})
                    geneset_config = nnea_config.get('geneset_layer', {})
                    geneset_config['num_genesets'] = best_num_genesets
                    nnea_config['geneset_layer'] = geneset_config
                    best_config['nnea'] = nnea_config
                    
                    # åˆ›å»ºæ–°çš„æ¨¡å‹å®ä¾‹
                    if config.get('global').get('model') == "nnea_classifier":
                        from .nnea_classifier import NNEAClassifier
                        best_model = NNEAClassifier(best_config)
                        best_model.build(nadata)
                    elif config.get('global').get('model') == "nnea_survival":
                        from .nnea_survival import NNEASurvival
                        best_model = NNEASurvival(best_config)
                        best_model.build(nadata)
                    elif config.get('global').get('model') == "nnea_regression":
                        from .nnea_regresser import NNEARegresser
                        best_model = NNEARegresser(best_config)
                        best_model.build(nadata)

                    # åŠ è½½æœ€ä½³æ¨¡å‹çŠ¶æ€
                    best_model.model.load_state_dict(best_model_state)
                    best_model.device = current_model.device
                    best_model.model = best_model.model.to(best_model.device)
                    
                    # æ›´æ–°å½“å‰æ¨¡å‹ä¸ºæœ€ä½³æ¨¡å‹
                    current_model = best_model
                    logger.info(f"âœ… æˆåŠŸä»æœ€ä½³æ¨¡å‹çŠ¶æ€é‡å»ºæ¨¡å‹ï¼ŒåŸºå› é›†æ•°é‡: {best_num_genesets}")
                else:
                    raise ValueError("æ— æ³•ä»æœ€ä½³æ¨¡å‹çŠ¶æ€æ¨æ–­åŸºå› é›†æ•°é‡")
                    
            except Exception as e:
                logger.error(f"âŒ ä»æœ€ä½³æ¨¡å‹çŠ¶æ€é‡å»ºæ¨¡å‹å¤±è´¥: {e}")
                logger.warning("âš ï¸ å°†ä½¿ç”¨å½“å‰æ¨¡å‹ä½œä¸ºæœ€ç»ˆæ¨¡å‹")
                # ä¿å­˜å½“å‰æ¨¡å‹ä½œä¸ºæœ€ç»ˆæ¨¡å‹
                final_model_path = os.path.join(outdir, "final_model.pth")
                torch.save(current_model.model.state_dict(), final_model_path)
                logger.info(f"ğŸ’¾ å½“å‰æ¨¡å‹å·²ä¿å­˜åˆ°: {final_model_path}")
        else:
            # å‚æ•°ç»´åº¦åŒ¹é…ï¼Œç›´æ¥åŠ è½½
            current_model.model.load_state_dict(best_model_state)
        
        # æ›´æ–°nadataä¸­çš„æ¨¡å‹ä¸ºæœ€ä½³æ¨¡å‹
        nadata.Model.add_model(f"{model_type}_best", current_model)
        
        # ä¿å­˜æœ€ç»ˆçš„æœ€ä½³æ¨¡å‹
        final_best_model_path = os.path.join(outdir, "best_model_final.pth")
        torch.save(best_model_state, final_best_model_path)
        
        final_best_nadata_path = os.path.join(outdir, "best_nadata_final.pkl")
        try:
            nadata.save(final_best_nadata_path, format="pickle", save_data=True)
            logger.info(f"ğŸ’¾ æœ€ç»ˆæœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ°: {final_best_model_path}")
            logger.info(f"ğŸ’¾ æœ€ç»ˆæœ€ä½³nadataå·²ä¿å­˜åˆ°: {final_best_nadata_path}")
        except Exception as e:
            logger.error(f"ä¿å­˜æœ€ç»ˆæœ€ä½³æ¨¡å‹å¤±è´¥: {e}")
    else:
        logger.warning("âš ï¸ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹çŠ¶æ€ï¼Œä½¿ç”¨å½“å‰æ¨¡å‹")
        # ä¿å­˜å½“å‰æ¨¡å‹ä½œä¸ºæœ€ç»ˆæ¨¡å‹
        final_model_path = os.path.join(outdir, "final_model.pth")
        torch.save(current_model.model.state_dict(), final_model_path)
        logger.info(f"ğŸ’¾ å½“å‰æ¨¡å‹å·²ä¿å­˜åˆ°: {final_model_path}")
    
    # åˆå¹¶è®­ç»ƒç»“æœ
    combined_results = {
        'stage_results': stage_results,
        'tailor_history': tailor_history,
        'tailor_info': {
            'tailor_epoch': tailor_epoch,
            'tailor_geneset': tailor_geneset,
            'total_stages': len(stage_results),
            'final_geneset_count': current_model.model.num_genesets if hasattr(current_model.model, 'num_genesets') else 'unknown',
            'best_stage': best_stage,
            'best_val_loss': best_val_loss,
            'early_stopped': no_improvement_count >= max_no_improvement,
            'no_improvement_count': no_improvement_count
        }
    }
    
    logger.info(f"å¾ªç¯Tailorç­–ç•¥è®­ç»ƒå®Œæˆï¼Œå…±è¿›è¡Œäº†{len(stage_results)}ä¸ªé˜¶æ®µ")
    if no_improvement_count >= max_no_improvement:
        logger.info(f"è®­ç»ƒå› æ—©åœè€Œç»“æŸï¼Œæœ€ä½³æ¨¡å‹æ¥è‡ªç¬¬{best_stage}é˜¶æ®µ")
    else:
        logger.info(f"è®­ç»ƒæ­£å¸¸å®Œæˆï¼Œæœ€ä½³æ¨¡å‹æ¥è‡ªç¬¬{best_stage}é˜¶æ®µ")
    
    return combined_results

def _crop_nnea_model(nadata, model, important_indices: np.ndarray, config: Dict[str, Any]):
    """
    è£å‰ªNNEAæ¨¡å‹ï¼Œç§»é™¤ä¸é‡è¦çš„åŸºå› é›†
    
    Args:
        nadata: nadataå¯¹è±¡
        model: åŸå§‹æ¨¡å‹
        important_indices: è¦ä¿ç•™çš„åŸºå› é›†ç´¢å¼•
        config: æ¨¡å‹é…ç½®
        
    Returns:
        è£å‰ªåçš„æ¨¡å‹
    """
    logger = logging.getLogger(__name__)
    
    # åˆ›å»ºæ–°çš„é…ç½®
    cropped_config = config.copy()
    
    # æ›´æ–°åŸºå› é›†æ•°é‡
    nnea_config = cropped_config.get('nnea', {})
    geneset_config = nnea_config.get('geneset_layer', {})
    original_num_genesets = geneset_config.get('num_genesets', 20)
    new_num_genesets = len(important_indices)
    
    geneset_config['num_genesets'] = new_num_genesets
    nnea_config['geneset_layer'] = geneset_config
    cropped_config['nnea'] = nnea_config
    
    logger.info(f"è£å‰ªåŸºå› é›†æ•°é‡: {original_num_genesets} -> {new_num_genesets}")
    
    # åˆ›å»ºæ–°çš„æ¨¡å‹å®ä¾‹
    if cropped_config.get('global').get("model") == 'nnea_classifier':
        from .nnea_classifier import NNEAClassifier
        cropped_model = NNEAClassifier(cropped_config)
    elif cropped_config.get('global').get('model') == 'nnea_survival':
        from .nnea_survival import NNEASurvival
        cropped_model = NNEASurvival(cropped_config)
    elif cropped_config.get('global').get('model') == 'nnea_regression':
        from .nnea_regresser import NNEARegresser
        cropped_model = NNEARegresser(cropped_config)
    # æ„å»ºæ–°æ¨¡å‹
    cropped_model.build(nadata)
    
    # è·å–åŸå§‹æ¨¡å‹çš„åŸºå› é›†å±‚å‚æ•°
    original_geneset_params = model.model.geneset_layer.get_geneset_parameters()
    
    # è®¾ç½®è£å‰ªåæ¨¡å‹çš„åŸºå› é›†å±‚å‚æ•°
    important_indices_tensor = torch.tensor(important_indices, dtype=torch.long)
    cropped_model.model.geneset_layer.set_geneset_parameters(original_geneset_params, important_indices_tensor)
    
    # å¤åˆ¶å…¶ä»–å±‚çš„å‚æ•°
    # original_state_dict = model.model.state_dict()
    # cropped_state_dict = cropped_model.model.state_dict()
    #
    # for key in original_state_dict:
    #     if key not in cropped_state_dict:
    #         continue
    #
    #     # è·³è¿‡åŸºå› é›†å±‚çš„å‚æ•°ï¼Œå› ä¸ºå·²ç»å•ç‹¬å¤„ç†
    #     if 'geneset_layer' in key:
    #         continue
    #     else:
    #         # éåŸºå› é›†å±‚å‚æ•°ç›´æ¥å¤åˆ¶
    #         cropped_state_dict[key] = original_state_dict[key]
    #
    # # ç‰¹æ®Šå¤„ç†focus_layerçš„ç¬¬ä¸€å±‚å‚æ•°
    # # ç”±äºgeneset_layerçš„è¾“å‡ºç»´åº¦å‘ç”Ÿäº†å˜åŒ–ï¼Œfocus_layerçš„ç¬¬ä¸€å±‚éœ€è¦ç›¸åº”è°ƒæ•´
    # # _update_focus_layer_parameters(model.model, cropped_model.model, important_indices)
    #
    # # åŠ è½½è£å‰ªåçš„å‚æ•°
    # cropped_model.model.load_state_dict(cropped_state_dict)
    
    # è®¾ç½®è®¾å¤‡
    cropped_model.device = model.device
    cropped_model.model = cropped_model.model.to(cropped_model.device)
    
    logger.info("æ¨¡å‹è£å‰ªå®Œæˆ")
    return cropped_model


def _update_focus_layer_parameters(original_model, cropped_model, important_indices: np.ndarray):
    """
    æ›´æ–°focus_layerçš„å‚æ•°ï¼Œä»¥é€‚åº”geneset_layerè¾“å‡ºç»´åº¦çš„å˜åŒ–
    
    Args:
        original_model: åŸå§‹æ¨¡å‹
        cropped_model: è£å‰ªåçš„æ¨¡å‹
        important_indices: è¦ä¿ç•™çš„åŸºå› é›†ç´¢å¼•
    """
    logger = logging.getLogger(__name__)
    
    # è·å–åŸå§‹å’Œè£å‰ªåçš„focus_layer
    original_focus_layer = original_model.focus_layer
    cropped_focus_layer = cropped_model.focus_layer
    
    if not isinstance(original_focus_layer, nn.Sequential) or not isinstance(cropped_focus_layer, nn.Sequential):
        logger.warning("focus_layerä¸æ˜¯Sequentialç»“æ„ï¼Œè·³è¿‡å‚æ•°æ›´æ–°")
        return
    
    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªLinearå±‚ï¼ˆé€šå¸¸æ˜¯focus_layerçš„ç¬¬ä¸€å±‚ï¼‰
    first_linear_layer = None
    first_linear_idx = None
    
    for i, layer in enumerate(original_focus_layer):
        if isinstance(layer, nn.Linear):
            first_linear_layer = layer
            first_linear_idx = i
            break
    
    if first_linear_layer is None:
        logger.warning("æœªæ‰¾åˆ°Linearå±‚ï¼Œè·³è¿‡focus_layerå‚æ•°æ›´æ–°")
        return
    
    # è·å–è£å‰ªåæ¨¡å‹çš„ç¬¬ä¸€å±‚Linearå±‚
    cropped_first_linear = cropped_focus_layer[first_linear_idx]
    
    if not isinstance(cropped_first_linear, nn.Linear):
        logger.warning("è£å‰ªåæ¨¡å‹çš„ç¬¬ä¸€å±‚ä¸æ˜¯Linearå±‚ï¼Œè·³è¿‡å‚æ•°æ›´æ–°")
        return
    
    # æ£€æŸ¥ç»´åº¦æ˜¯å¦åŒ¹é…
    original_input_dim = first_linear_layer.in_features
    cropped_input_dim = cropped_first_linear.in_features
    
    if original_input_dim != len(important_indices):
        logger.warning(f"ç»´åº¦ä¸åŒ¹é…: åŸå§‹è¾“å…¥ç»´åº¦ {original_input_dim}, é‡è¦ç´¢å¼•æ•°é‡ {len(important_indices)}")
        return
    
    # æ›´æ–°æƒé‡ï¼šåªä¿ç•™å¯¹åº”é‡è¦åŸºå› é›†çš„æƒé‡
    original_weight = first_linear_layer.weight.data
    original_bias = first_linear_layer.bias.data if first_linear_layer.bias is not None else None
    
    # é€‰æ‹©å¯¹åº”é‡è¦åŸºå› é›†çš„æƒé‡è¡Œ
    important_indices_tensor = torch.tensor(important_indices, dtype=torch.long, device=original_weight.device)
    cropped_weight = original_weight[:, important_indices_tensor]
    
    # æ›´æ–°è£å‰ªåæ¨¡å‹çš„æƒé‡
    cropped_first_linear.weight.data = cropped_weight
    
    # åç½®é¡¹ä¿æŒä¸å˜ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    if original_bias is not None and cropped_first_linear.bias is not None:
        cropped_first_linear.bias.data = original_bias.clone()
    
    logger.info(f"focus_layerç¬¬ä¸€å±‚å‚æ•°æ›´æ–°å®Œæˆ: è¾“å…¥ç»´åº¦ {original_input_dim} -> {cropped_input_dim}")

def eval(nadata, split='test', model_name: Optional[str] = None) -> Dict[str, float]:
    """
    è¯„ä¼°æ¨¡å‹
    
    Args:
        nadata: nadataå¯¹è±¡
        split: è¯„ä¼°çš„æ•°æ®é›†åˆ†å‰²
        model_name: æ¨¡å‹åç§°
        
    Returns:
        è¯„ä¼°ç»“æœ
    """
    if not nadata.Model.models:
        raise ValueError("nadata.Modelä¸­æ²¡æœ‰æ¨¡å‹ï¼Œè¯·å…ˆè°ƒç”¨build()")
    
    # ç¡®å®šè¦è¯„ä¼°çš„æ¨¡å‹
    if model_name is None:
        model_type = nadata.Model.get_config().get('global', {}).get('model', 'nnea')
        model = nadata.Model.get_model(model_type)
    else:
        model = nadata.Model.get_model(model_name)
    
    if model is None:
        raise ValueError(f"æœªæ‰¾åˆ°æ¨¡å‹: {model_name or 'default'}")
    
    # è¯„ä¼°æ¨¡å‹
    return model.evaluate(nadata, split)

def explain(nadata, method='importance', model_name: Optional[str] = None) -> Dict[str, Any]:
    """
    è§£é‡Šæ¨¡å‹
    
    Args:
        nadata: nadataå¯¹è±¡
        method: è§£é‡Šæ–¹æ³•
        model_name: æ¨¡å‹åç§°
        
    Returns:
        è§£é‡Šç»“æœ
    """
    if not nadata.Model.models:
        raise ValueError("nadata.Modelä¸­æ²¡æœ‰æ¨¡å‹ï¼Œè¯·å…ˆè°ƒç”¨build()")
    
    # ç¡®å®šè¦è§£é‡Šçš„æ¨¡å‹
    if model_name is None:
        model_type = nadata.Model.get_config().get('global', {}).get('model', 'nnea')
        model = nadata.Model.get_model(model_type)
    else:
        model = nadata.Model.get_model(model_name)
    
    if model is None:
        raise ValueError(f"æœªæ‰¾åˆ°æ¨¡å‹: {model_name or 'default'}")
    
    # è§£é‡Šæ¨¡å‹
    return model.explain(nadata, method)

def save_model(nadata, save_path: str, model_name: Optional[str] = None) -> None:
    """
    ä¿å­˜æ¨¡å‹æˆ–æ•´ä¸ªnadataé¡¹ç›®
    
    Args:
        nadata: nadataå¯¹è±¡
        save_path: ä¿å­˜è·¯å¾„
        model_name: æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä¿å­˜æ•´ä¸ªé¡¹ç›®
    """
    if model_name is None:
        # ä¿å­˜æ•´ä¸ªé¡¹ç›®
        nadata.save(save_path)
        logger.info(f"é¡¹ç›®å·²ä¿å­˜åˆ°: {save_path}")
    else:
        # ä¿å­˜ç‰¹å®šæ¨¡å‹
        model = nadata.Model.get_model(model_name)
        if model is None:
            raise ValueError(f"æœªæ‰¾åˆ°æ¨¡å‹: {model_name}")
        
        # ä¿å­˜æ¨¡å‹çŠ¶æ€
        torch.save(model.state_dict(), save_path)
        logger.info(f"æ¨¡å‹ {model_name} å·²ä¿å­˜åˆ°: {save_path}")

def load_project(load_path: str):
    """
    åŠ è½½nadataé¡¹ç›®
    
    Args:
        load_path: åŠ è½½è·¯å¾„
        
    Returns:
        nadataå¯¹è±¡
    """
    from ..io._load import load_project as load_project_impl
    return load_project_impl(load_path)

def get_summary(nadata) -> Dict[str, Any]:
    """
    è·å–nadataæ‘˜è¦ä¿¡æ¯
    
    Args:
        nadata: nadataå¯¹è±¡
        
    Returns:
        æ‘˜è¦ä¿¡æ¯å­—å…¸
    """
    summary = {
        'data_info': {},
        'model_info': {},
        'config_info': {}
    }
    
    # æ•°æ®ä¿¡æ¯
    if nadata.X is not None:
        summary['data_info']['X_shape'] = nadata.X.shape
    if nadata.Meta is not None:
        summary['data_info']['Meta_shape'] = nadata.Meta.shape
    if nadata.Var is not None:
        summary['data_info']['Var_shape'] = nadata.Var.shape
    if nadata.Prior is not None:
        summary['data_info']['Prior_shape'] = nadata.Prior.shape
    
    # æ¨¡å‹ä¿¡æ¯
    summary['model_info']['models'] = nadata.Model.list_models()
    summary['model_info']['config_keys'] = list(nadata.Model.get_config().keys())
    summary['model_info']['train_results_keys'] = list(nadata.Model.get_train_results().keys())
    
    # é…ç½®ä¿¡æ¯
    config = nadata.Model.get_config()
    if config:
        summary['config_info']['model_type'] = config.get('global', {}).get('model', 'unknown')
        summary['config_info']['task'] = config.get('global', {}).get('task', 'unknown')
        summary['config_info']['device'] = config.get('global', {}).get('device', 'cpu')
    
    return summary

def train_classification_models(nadata, config: Optional[Dict[str, Any]] = None, verbose: int = 1) -> Dict[str, Any]:
    """
    è®­ç»ƒåˆ†ç±»æ¨¡å‹
    
    Args:
        nadata: nadataå¯¹è±¡
        config: é…ç½®å­—å…¸
        verbose: è¯¦ç»†ç¨‹åº¦
        
    Returns:
        è®­ç»ƒç»“æœ
    """
    from sklearn.linear_model import LogisticRegression
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
    from sklearn.svm import SVC
    from sklearn.metrics import accuracy_score, roc_auc_score, classification_report
    import numpy as np
    
    # è·å–é…ç½®
    if config is None:
        config = nadata.Model.get_config()
    
    # è·å–æ•°æ®
    X_train = nadata.X[:, nadata.Model.get_indices('train')]
    X_test = nadata.X[:, nadata.Model.get_indices('test')]
    
    # è·å–ç›®æ ‡åˆ—åç§°
    target_column = 'class'  # é»˜è®¤ä½¿ç”¨'class'
    if config and 'dataset' in config:
        target_column = config['dataset'].get('target_column', 'class')
    
    y_train = nadata.Meta.iloc[nadata.Model.get_indices('train')][target_column].values
    y_test = nadata.Meta.iloc[nadata.Model.get_indices('test')][target_column].values
    
    # å®šä¹‰è¦è®­ç»ƒçš„æ¨¡å‹
    models_to_train = config.get('classification', {}).get('models', ['logistic_regression', 'random_forest'])
    
    results = {
        'models': {},
        'comparison_df': None
    }
    
    for model_name in models_to_train:
        if verbose >= 1:
            print(f"è®­ç»ƒ {model_name}...")
        
        if model_name == 'logistic_regression':
            model = LogisticRegression(random_state=42, max_iter=1000)
        elif model_name == 'random_forest':
            model = RandomForestClassifier(n_estimators=100, random_state=42)
        elif model_name == 'gradient_boosting':
            model = GradientBoostingClassifier(random_state=42)
        elif model_name == 'support_vector_machine':
            model = SVC(probability=True, random_state=42)
        else:
            if verbose >= 1:
                print(f"è·³è¿‡æœªçŸ¥æ¨¡å‹: {model_name}")
            continue
        
        # è®­ç»ƒæ¨¡å‹
        model.fit(X_train.T, y_train)
        
        # é¢„æµ‹
        y_pred = model.predict(X_test.T)
        y_pred_proba = model.predict_proba(X_test.T)[:, 1]
        
        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(y_test, y_pred)
        auc = roc_auc_score(y_test, y_pred_proba)
        
        # ä¿å­˜ç»“æœ
        results['models'][model_name] = {
            'model': model,
            'accuracy': accuracy,
            'auc': auc,
            'predictions': y_pred,
            'probabilities': y_pred_proba
        }
        
        # æ·»åŠ åˆ°nadataçš„Modelå®¹å™¨
        nadata.Model.add_model(f'classification_{model_name}', model)
        
        if verbose >= 1:
            print(f"  {model_name} - å‡†ç¡®ç‡: {accuracy:.4f}, AUC: {auc:.4f}")
    
    # åˆ›å»ºæ¯”è¾ƒDataFrame
    if results['models']:
        comparison_data = []
        for name, result in results['models'].items():
            comparison_data.append({
                'model': name,
                'accuracy': result['accuracy'],
                'auc': result['auc']
            })
        
        import pandas as pd
        results['comparison_df'] = pd.DataFrame(comparison_data)
    
    return results

def compare_models(nadata, config: Optional[Dict[str, Any]] = None, verbose: int = 1) -> Dict[str, Any]:
    """
    æ¯”è¾ƒä¸åŒæ¨¡å‹çš„æ€§èƒ½
    
    Args:
        nadata: nadataå¯¹è±¡
        config: é…ç½®å­—å…¸
        verbose: è¯¦ç»†ç¨‹åº¦
        
    Returns:
        æ¯”è¾ƒç»“æœ
    """
    # è·å–æ‰€æœ‰æ¨¡å‹
    all_models = nadata.Model.list_models()
    
    if verbose >= 1:
        print(f"æ¯”è¾ƒ {len(all_models)} ä¸ªæ¨¡å‹: {all_models}")
    
    results = {
        'models': {},
        'comparison_df': None
    }
    
    # è·å–æµ‹è¯•æ•°æ®
    test_indices = nadata.Model.get_indices('test')
    if test_indices is None:
        raise ValueError("æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•é›†ç´¢å¼•")
    
    X_test = nadata.X[:, test_indices]
    
    # è·å–ç›®æ ‡åˆ—å
    target_column = nadata.Model.get_config().get('dataset', {}).get('target_column', 'class')
    y_test = nadata.Meta.iloc[test_indices][target_column].values
    
    for model_name in all_models:
        model = nadata.Model.get_model(model_name)
        if model is None:
            continue
        
        if verbose >= 1:
            print(f"è¯„ä¼° {model_name}...")
        
        try:
            # å¯¹äºNNEAæ¨¡å‹
            if hasattr(model, 'evaluate'):
                eval_result = model.evaluate(nadata, 'test')
                results['models'][model_name] = eval_result
            else:
                # å¯¹äºsklearnæ¨¡å‹
                y_pred = model.predict(X_test.T)
                y_pred_proba = model.predict_proba(X_test.T)[:, 1]
                
                from sklearn.metrics import accuracy_score, roc_auc_score
                accuracy = accuracy_score(y_test, y_pred)
                auc = roc_auc_score(y_test, y_pred_proba)
                
                results['models'][model_name] = {
                    'accuracy': accuracy,
                    'auc': auc
                }
            
            if verbose >= 1:
                if 'accuracy' in results['models'][model_name]:
                    print(f"  {model_name} - å‡†ç¡®ç‡: {results['models'][model_name]['accuracy']:.4f}")
                if 'auc' in results['models'][model_name]:
                    print(f"  {model_name} - AUC: {results['models'][model_name]['auc']:.4f}")
                    
        except Exception as e:
            if verbose >= 1:
                print(f"  è¯„ä¼° {model_name} å¤±è´¥: {e}")
            continue
    
    # åˆ›å»ºæ¯”è¾ƒDataFrame
    if results['models']:
        comparison_data = []
        for name, result in results['models'].items():
            row = {'model': name}
            if 'accuracy' in result:
                row['accuracy'] = result['accuracy']
            if 'auc' in result:
                row['auc'] = result['auc']
            comparison_data.append(row)
        
        import pandas as pd
        results['comparison_df'] = pd.DataFrame(comparison_data)
    
    return results

def predict(nadata, split='test', model_name: Optional[str] = None, return_probabilities: bool = True) -> Dict[str, Any]:
    """
    æ¨¡å‹é¢„æµ‹

    Args:
        nadata: nadataå¯¹è±¡
        split: é¢„æµ‹çš„æ•°æ®é›†åˆ†å‰²
        model_name: æ¨¡å‹åç§°
        return_probabilities: æ˜¯å¦è¿”å›æ¦‚ç‡å€¼

    Returns:
        é¢„æµ‹ç»“æœå­—å…¸ï¼ŒåŒ…å«é¢„æµ‹å€¼ã€æ¦‚ç‡å€¼ã€çœŸå®æ ‡ç­¾ç­‰
    """
    from sklearn.metrics import classification_report, roc_auc_score, mean_squared_error, mean_absolute_error, r2_score
    import torch

    logger = logging.getLogger(__name__)

    if not nadata.Model.models:
        raise ValueError("nadata.Modelä¸­æ²¡æœ‰æ¨¡å‹ï¼Œè¯·å…ˆè°ƒç”¨build()")

    # ç¡®å®šè¦é¢„æµ‹çš„æ¨¡å‹
    if model_name is None:
        model_type = nadata.Model.get_config().get('global', {}).get('model', 'nnea')
        model = nadata.Model.get_model(model_type)
    else:
        model = nadata.Model.get_model(model_name)

    if model is None:
        raise ValueError(f"æœªæ‰¾åˆ°æ¨¡å‹: {model_name or 'default'}")

    # è·å–æ•°æ®ç´¢å¼•
    indices = nadata.Model.get_indices(split)
    if indices is None:
        logger.warning(f"æœªæ‰¾åˆ°{split}é›†çš„ç´¢å¼•ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹")
        return {
            'y_test': None,
            'y_pred': None,
            'y_proba': None,
            'predictions': None,
            'error': f"æœªæ‰¾åˆ°{split}é›†çš„ç´¢å¼•"
        }

    try:
        # è·å–æµ‹è¯•é›†æ•°æ®
        X_test = nadata.X[indices]  # è½¬ç½®ä¸º(æ ·æœ¬æ•°, ç‰¹å¾æ•°)

        # è·å–ç›®æ ‡åˆ—å
        config = nadata.Model.get_config()
        target_col = config.get('dataset', {}).get('target_column', 'target')
        y_test = nadata.Meta.iloc[indices][target_col].values

        logger.info(f"ğŸ”® è¿›è¡Œæ¨¡å‹é¢„æµ‹...")
        logger.info(f"ğŸ“Š æµ‹è¯•é›†å½¢çŠ¶: X_test={X_test.shape}, y_test={y_test.shape}")

        # æ¨¡å‹é¢„æµ‹
        model.model.eval()
        with torch.no_grad():
            X_test_tensor = torch.FloatTensor(X_test).to(model.device)
            outputs = model.model(X_test_tensor)

        # æ ¹æ®ä»»åŠ¡ç±»å‹å¤„ç†é¢„æµ‹ç»“æœ
        task_type = getattr(model, 'task', 'classification')
        
        if task_type == 'classification':
            # åˆ†ç±»ä»»åŠ¡å¤„ç†
            if outputs.shape[1] == 2:
                # äºŒåˆ†ç±»æƒ…å†µ
                y_proba = torch.softmax(outputs, dim=1).cpu().numpy()[:, 1]
                y_pred = (y_proba > 0.5).astype(int)
            else:
                # å¤šåˆ†ç±»æƒ…å†µ
                y_proba = torch.softmax(outputs, dim=1).cpu().numpy()
                y_pred = np.argmax(y_proba, axis=1)

            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
            if len(np.unique(y_test)) == 2:
                # äºŒåˆ†ç±»
                auc = roc_auc_score(y_test, y_proba)
                logger.info(f"ğŸ“Š æµ‹è¯•é›†AUCï¼š{auc:.4f}")
            else:
                # å¤šåˆ†ç±»
                auc = roc_auc_score(y_test, y_proba, multi_class='ovr')
                logger.info(f"ğŸ“Š æµ‹è¯•é›†AUCï¼š{auc:.4f}")

            # è¾“å‡ºåˆ†ç±»æŠ¥å‘Š
            logger.info("ğŸ“Š é¢„æµ‹ç»“æœ:")
            logger.info(f"æµ‹è¯•é›†åˆ†ç±»æŠ¥å‘Šï¼š\n{classification_report(y_test, y_pred)}")

            # ä¿å­˜é¢„æµ‹ç»“æœåˆ°Modelå®¹å™¨
            prediction_results = {
                'y_test': y_test,
                'y_pred': y_pred,
                'y_proba': y_proba,
                'predictions': outputs.cpu().numpy(),
                'auc': auc,
                'split': split,
                'task_type': 'classification'
            }

        elif task_type == 'survival':
            # ç”Ÿå­˜ä»»åŠ¡å¤„ç†
            time_col = config.get('dataset', {}).get('time_column', 'Time')
            event_col = config.get('dataset', {}).get('event_column', 'Event')
            
            times = nadata.Meta.iloc[indices][time_col].values
            events = nadata.Meta.iloc[indices][event_col].values
            
            # ç”Ÿå­˜åˆ†æé¢„æµ‹ç»“æœ
            risk_scores = outputs.cpu().numpy().flatten()
            
            # è®¡ç®—ç”Ÿå­˜åˆ†ææŒ‡æ ‡
            from lifelines.utils import concordance_index
            c_index = concordance_index(times, -risk_scores, events)
            
            logger.info(f"ğŸ“Š æµ‹è¯•é›†C-indexï¼š{c_index:.4f}")
            
            # ä¿å­˜é¢„æµ‹ç»“æœåˆ°Modelå®¹å™¨
            prediction_results = {
                'times': times,
                'events': events,
                'risk_scores': risk_scores,
                'predictions': outputs.cpu().numpy(),
                'c_index': c_index,
                'split': split,
                'task_type': 'survival'
            }

        elif task_type == 'regression':
            # å›å½’ä»»åŠ¡å¤„ç†
            predictions = outputs.cpu().numpy().flatten()
            
            # è®¡ç®—å›å½’è¯„ä¼°æŒ‡æ ‡
            mse = mean_squared_error(y_test, predictions)
            mae = mean_absolute_error(y_test, predictions)
            r2 = r2_score(y_test, predictions)
            rmse = np.sqrt(mse)
            
            logger.info(f"ğŸ“Š æµ‹è¯•é›†å›å½’æŒ‡æ ‡ï¼š")
            logger.info(f"  MSE: {mse:.4f}")
            logger.info(f"  MAE: {mae:.4f}")
            logger.info(f"  RÂ²: {r2:.4f}")
            logger.info(f"  RMSE: {rmse:.4f}")
            
            # ä¿å­˜é¢„æµ‹ç»“æœåˆ°Modelå®¹å™¨
            prediction_results = {
                'y_test': y_test,
                'predictions': predictions,
                'mse': mse,
                'mae': mae,
                'r2': r2,
                'rmse': rmse,
                'split': split,
                'task_type': 'regression'
            }

        else:
            # å…¶ä»–ä»»åŠ¡ç±»å‹
            predictions = outputs.cpu().numpy()
            prediction_results = {
                'y_test': y_test,
                'predictions': predictions,
                'split': split,
                'task_type': task_type
            }

        # ä¿å­˜åˆ°nadataçš„Modelå®¹å™¨
        nadata.Model.add_metadata('prediction_results', prediction_results)

        logger.info(f"âœ… æ¨¡å‹é¢„æµ‹å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°nadata.Model")

        return prediction_results

    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
        return {
            'y_test': None,
            'y_pred': None,
            'y_proba': None,
            'predictions': None,
            'error': str(e)
        }