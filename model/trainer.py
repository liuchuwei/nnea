import os

import numpy as np
import pandas as pd
import torch
from sklearn.model_selection import RandomizedSearchCV, ParameterSampler
from torch import nn
import torch.nn.functional as F
import joblib

import shutil
from utils.train_utils import cox_loss, BuildOptimizer, LoadModel
from sklearn.metrics import (
    accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report, RocCurveDisplay,
    mean_squared_error, mean_absolute_error, r2_score, silhouette_score
)

class CrossTrainer(object):

    def __init__(self, trainer_config, model_config, global_config, loader):
        self.model_config = {**global_config, **model_config, **trainer_config}
        self.loader = loader
        self.best_params = None  # å­˜å‚¨æœ€ä½³å‚æ•°
        self.best_score = -float('inf')  # å­˜å‚¨æœ€ä½³å¾—åˆ†

    def train_single_model(self, fold_data):

        model = LoadModel(self.model_config, self.loader)

        # åˆ›å»ºTrainerå¹¶è®­ç»ƒ
        trainer = Trainer(self.model_config, model, fold_data)
        trainer.train()

        # è¿”å›éªŒè¯é›†æ€§èƒ½
        return trainer.get_validation_metric()

    def save_cv_results(self, results):
        """ä¿å­˜äº¤å‰éªŒè¯ç»“æœ"""
        df = pd.DataFrame([{
            'params': str(r[0]),
            'avg_score': r[1],
            'fold_scores': str(r[2])
        } for r in results])
        df.to_csv(os.path.join(self.model_config['checkpoint_dir'], 'cv_results.csv'), index=False)

    def train(self):

        param_grid = {
            "lr" : self.model_config['lr'],
            "weight_decay" : self.model_config['weight_decay'],
            "classifier_dropout": self.model_config['classifier_dropout'],
            "num_sets": range(self.model_config['num_sets'][0],
                              self.model_config['num_sets'][1],
                              self.model_config['num_sets'][2]),
            "batch_size" : self.model_config['batch_size'],
        }

        param_samples = list(ParameterSampler(param_grid, n_iter=self.model_config['n_iter']))
        results = []

        for params in param_samples:
            print(f"\nEvaluating hyperparameters: {params}")
            fold_scores = []
            self.model_config.update(params)
            for item in self.loader.cv_loaders:

                score = self.train_single_model(item)
                fold_scores.append(score)

            avg_score = np.mean(fold_scores)
            results.append((params, avg_score, fold_scores))

            # æ›´æ–°æœ€ä½³å‚æ•°
            if avg_score > self.best_score:
                self.best_score = avg_score
                self.best_params = params
                best_fold = np.argmax(fold_scores)
                print(f"ğŸ”¥ New best params! Score: {avg_score:.4f}")


        print(f"\nğŸš€ Training final model with best params: {self.best_params}")
        self.model_config.update(self.best_params)
        final_model = LoadModel(self.model_config, self.loader)
        final_trainer = Trainer(self.model_config, final_model, self.loader.cv_loaders[best_fold])
        final_trainer.train()
        test_loader = torch.utils.data.DataLoader(
            self.loader.test_dataset,
            batch_size=self.model_config['batch_size'],
            shuffle=False
        )
        final_trainer.evaluate(loader=test_loader)

        print(classification_report(final_trainer.all_targets, final_trainer.all_predictions))

        with open(os.path.join(self.model_config['checkpoint_dir'], "test_result.txt"), 'w') as f:
            f.write(classification_report(final_trainer.all_targets, final_trainer.all_predictions))

        # ä¿å­˜äº¤å‰éªŒè¯ç»“æœ
        results.append((self.best_params, "<-best param; best fold->", best_fold))
        self.save_cv_results(results)
class Trainer(object):

    def __init__(self, config, model, loader):

        self.config = config
        self.model = model
        self.loader = loader

        if config['model'] == "nnea":
            self.init_nnea()

    def init_nnea(self):
        # self.loader = self.loader.torch_loader

        self.train_loader = torch.utils.data.DataLoader(
            self.loader['train'],
            batch_size=self.config['batch_size'],
            shuffle=True
        )
        self.valid_loader = torch.utils.data.DataLoader(
            self.loader['valid'],
            batch_size=self.config['batch_size'],
            shuffle=False
        )

        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)  # è£å‰ªæ¢¯åº¦
        self.scheduler, self.optimizer = BuildOptimizer(params=self.model.parameters(), config=self.config)


        if self.config['task'] == "umap":
            self.umap_loss = UMAP_Loss(
                n_neighbors=self.config['n_neighbors'],
                min_dist=self.config['min_dist']
            )


    def evaluate(self, loader):

        self.model.eval()
        total_samples = 0
        pos_samples = 0
        neg_samples = 0
        pos_risk = 0
        neg_risk = 0
        correct = 0
        mse_loss = 0.0
        mae_loss = 0.0
        recon_loss = 0.0
        silhouette_loss = 0.0
        all_predictions = []  # å­˜å‚¨æ‰€æœ‰é¢„æµ‹å€¼
        all_targets = []  # å­˜å‚¨æ‰€æœ‰çœŸå®æ ‡ç­¾

        with torch.no_grad():
            for batch_data in loader:

                device = self.config['device']
                batch_R, batch_S = batch_data[0].to(device),  batch_data[1].to(
                    device)

                # å‰å‘ä¼ æ’­
                logits = self.model(batch_R, batch_S)

                total_samples += batch_data[0].size(0)

                if self.config['task'] in ['classification']:

                    _, predicted = torch.max(logits, 1)
                    batch_y = batch_data[2]
                    correct += (predicted == batch_y.squeeze().to(self.config["device"])).sum().item()

                    # ç´¯ç§¯é¢„æµ‹å€¼å’Œæ ‡ç­¾
                    all_predictions.append(predicted.cpu())
                    all_targets.append(batch_y.cpu())

                elif self.config['task'] in ['cox']:
                    events = batch_data[3]
                    pos_samples += sum(events == 1)
                    neg_samples += sum(events == 0)
                    pos_risk += torch.sum(logits[events == 1])
                    neg_risk += torch.sum(logits[events == 0])

                elif self.config['task'] in ['regression']:
                    predictions = logits.squeeze()
                    batch_y = batch_data[2].to(device, dtype=torch.float)

                    # è®¡ç®— MSE å’Œ MAE
                    mse_loss += nn.MSELoss()(predictions, batch_y).item() * len(batch_y)
                    mae_loss += nn.L1Loss()(predictions, batch_y).item() * len(batch_y)

                    # ç´¯ç§¯é¢„æµ‹å€¼å’Œæ ‡ç­¾
                    all_predictions.append(predictions.cpu())
                    all_targets.append(batch_y.cpu())

                elif self.config['task'] in ['autoencoder']:
                    enc_exp = logits
                    norm_exp = batch_data[2].to(device, dtype=torch.float)
                    batch_recon_loss = F.mse_loss(enc_exp, norm_exp).item()
                    recon_loss += batch_recon_loss * batch_R.size(0)

                elif self.config['task'] in ['umap']:
                    embeddings = logits.cpu().detach()
                    labels = batch_data[3].cpu().detach()# å‡è®¾batch_data[1]æ˜¯ç»†èƒç±»å‹
                    all_predictions.append(embeddings)
                    all_targets.append(labels)


            if self.config['task'] in ['classification']:
                self.accuracy = correct / total_samples

                # è®¡ç®—æ··æ·†çŸ©é˜µå’ŒF1åˆ†æ•°
                all_preds = torch.cat(all_predictions).numpy()
                all_targets = torch.cat(all_targets).numpy()

                self.all_predictions = all_preds
                self.all_targets = all_targets

                # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒF1åˆ†æ•°
                self.classification_report = classification_report(
                    all_targets, all_preds,
                    target_names=self.config['class_names'],
                    output_dict=True,
                    zero_division=0  # æˆ– 1ï¼Œæ ¹æ®éœ€æ±‚è®¾ç½®
                )
                self.macro_f1 = self.classification_report['macro avg']['f1-score']
                self.weighted_f1 = self.classification_report['weighted avg']['f1-score']


            if self.config['task'] in ['autoencoder']:
                self.recon_loss = recon_loss / total_samples

            elif self.config['task'] in ['umap']:

                all_preds = torch.cat(all_predictions).numpy()
                all_targets = torch.cat(all_targets).numpy()

                self.silhouette_loss = silhouette_score(all_preds, all_targets)

            elif self.config['task'] in ['cox']:
                self.high_risk = pos_risk / total_samples
                self.low_risk = neg_risk / total_samples
                self.accuracy = self.high_risk - self.low_risk

            elif self.config['task'] == 'regression':
                self.mse = mse_loss / total_samples
                self.mae = mae_loss / total_samples

                all_preds = torch.cat(all_predictions).numpy()
                all_targets = torch.cat(all_targets).numpy()

                pearson_corr = np.corrcoef(all_preds, all_targets)[0, 1]
                self.pearson = pearson_corr if not np.isnan(pearson_corr) else 0.0

    def get_validation_metric(self):
        """è·å–éªŒè¯é›†æ€§èƒ½æŒ‡æ ‡"""

        # æ ¹æ®ä»»åŠ¡ç±»å‹è¿”å›å…³é”®æŒ‡æ ‡
        if self.config['task'] == "classification":
            return self.macro_f1
        elif self.config['task'] == "cox":
            return self.accuracy
        elif self.config['task'] == "regression":
            return -self.mse  # è´ŸMSEï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
        elif self.config['task'] == "umap":
            return self.silhouette_loss

    def get_task_loss(self, logits, batch_data, device):

        if self.config['task'] in ['classification']:
            log_probs = logits
            batch_y = batch_data[2].to(device, dtype=torch.long).squeeze()
            return nn.NLLLoss()(log_probs, batch_y)

        elif self.config['task'] in ['cox']:
            risks = logits
            times = batch_data[2].to(device)
            events = batch_data[3].to(device)
            return cox_loss(risks, times, events)

        elif self.config['task'] == 'regression':
            predictions = logits.squeeze()  # ç¡®ä¿è¾“å‡ºæ˜¯1Då‘é‡
            batch_y = batch_data[2].to(device, dtype=torch.float)
            return nn.MSELoss()(predictions, batch_y)

        elif self.config['task'] == 'autoencoder':
            enc_exp = logits  # ç¡®ä¿è¾“å‡ºæ˜¯1Då‘é‡
            norm_exp = batch_data[2].to(device, dtype=torch.float)

            return F.mse_loss(enc_exp, norm_exp)

        elif self.config['task'] == 'umap':
            embeddings = logits
            inputs = batch_data[2].to(device, dtype=torch.float)
            return self.umap_loss(embeddings, inputs)

    def calculate_loss(self, loader):

        self.model.eval()
        total_loss = 0.0

        # for batch_R, batch_S, batch_y in self.loader:
        for batch_data in loader:
            device = self.config['device']
            batch_R, batch_S = batch_data[0].to(device), batch_data[1].to(
                device)

            # å‰å‘ä¼ æ’­
            logits = self.model(batch_R, batch_S)

            # è®¡ç®—åˆ†ç±»æŸå¤±
            task_loss = self.get_task_loss(logits, batch_data, device=self.config['device'])

            # è®¡ç®—æ­£åˆ™åŒ–æŸå¤±
            reg_loss = self.model.regularization_loss()

            # æ€»æŸå¤±ï¼ˆåˆ†ç±»æŸå¤±+æ­£åˆ™åŒ–æŸå¤±ï¼‰
            total_batch_loss = task_loss + reg_loss

            total_loss += total_batch_loss.item()

        avg_loss = total_loss / len(self.loader)

        return avg_loss, task_loss, reg_loss

    def one_epoch(self):
        self.model.train()
        total_loss = 0.0

        # for batch_R, batch_S, batch_y in self.loader:
        for batch_data in self.train_loader:

            device = self.config['device']
            batch_R, batch_S = batch_data[0].to(device),  batch_data[1].to(
                device)

            self.optimizer.zero_grad()

            # å‰å‘ä¼ æ’­
            logits = self.model(batch_R, batch_S)

            # è®¡ç®—åˆ†ç±»æŸå¤±
            task_loss = self.get_task_loss(logits, batch_data, device=self.config['device'])

            # è®¡ç®—æ­£åˆ™åŒ–æŸå¤±
            reg_loss = self.model.regularization_loss()

            # æ€»æŸå¤±ï¼ˆåˆ†ç±»æŸå¤±+æ­£åˆ™åŒ–æŸå¤±ï¼‰
            total_batch_loss = task_loss + reg_loss

            # åå‘ä¼ æ’­
            total_batch_loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 2.0)
            self.optimizer.step()

            total_loss += total_batch_loss.item()

        avg_loss = total_loss / len(self.loader)

        return avg_loss, task_loss, reg_loss

    def save_checkpoint(self):

        checkpoint_dir = self.config['checkpoint_dir']
        if not os.path.exists(checkpoint_dir):  # å…ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨
                os.makedirs(checkpoint_dir)
                source_file = self.config['toml_path']
                dest_path = os.path.join(checkpoint_dir, os.path.basename(source_file))
                shutil.copy2(source_file, dest_path)  # å¤åˆ¶æ–‡ä»¶å¹¶ä¿ç•™å…ƒæ•°æ®[6,8](@ref)

        if self.config['model'] in ['nnea']:
            torch.save(self.model.state_dict(), os.path.join(self.config['checkpoint_dir'], "_checkpoint.pt"))

        elif self.config['model'] in ['LR']:
            test_metrics, test_pred = self.evaluate_model(self.model, self.loader.X_test, self.loader.y_test)
            print("best params: %s" % self.model.get_params)
            print("best metrics: %s" % test_metrics)
            print(classification_report(self.loader.y_test, test_pred))

            joblib.dump(self.model,  os.path.join(self.config['checkpoint_dir'], "_checkpoint.pkl"))
            with open(os.path.join(self.config['checkpoint_dir'], "test_result.txt"), 'w') as f:
                f.write(f"Best Params: {self.model.get_params}\n")
                f.write(f"Test Metrics: {test_metrics}\n")
                f.write("Classification Report:\n")
                f.write(classification_report(self.loader.y_test, test_pred))

            results_df = pd.DataFrame({
                'true_label': self.loader.y_test,
                'predicted_label': test_pred
            })
            results_df.to_csv(os.path.join(self.config['checkpoint_dir'], "'predictions.csv"), index=False)

    def save_model(self, epoch):

        # ä»»åŠ¡ç±»å‹ä¸ç›‘æ§æŒ‡æ ‡çš„æ˜ å°„
        if self.config['task'] == "cox":
            current_metric = self.accuracy
        elif self.config['task'] == "classification":
            current_metric = self.macro_f1
        elif self.config['task'] == "regression":
            current_metric = -self.mse  # è´Ÿå€¼æ–¹ä¾¿ç»Ÿä¸€é€»è¾‘ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
        elif self.config['task'] == "autoencoder":
            current_metric = -self.recon_loss
        elif self.config['task'] == "umap":
            current_metric = -self.silhouette_loss

        improved = current_metric > self.best_metric

        if improved:
            self.best_metric = current_metric
            self.save_checkpoint()

        return improved
    def print_process(self, epoch, task_loss, reg_loss, avg_loss):

        if self.config['task'] in ['classification']:

            info = (f"Epoch {epoch + 1}/{self.config['num_epochs']}, Loss: {avg_loss:.4f}, "
                  f"Task Loss: {task_loss.item():.4f}, Reg Loss: {reg_loss.item():.4f}, "
                  f"Train accuracy: {self.accuracy:.4f} "
                  f"Train macro f1: {self.macro_f1:.4f}, "
                  f"Train weighted f1: {self.weighted_f1:.4f}, "
                  )
            self.evaluate(loader=self.valid_loader)

            info += (f"Val accuracy: {self.accuracy:.4f} "
                  f"Val macro f1: {self.macro_f1:.4f}, "
                  f"Val weighted f1: {self.weighted_f1:.4f}")

            print(info)

        elif self.config['task'] in ['cox']:

            info = (f"Epoch {epoch + 1}/{self.config['num_epochs']}, Loss: {avg_loss:.4f}, "
                  f"Task Loss: {task_loss.item():.4f}, Reg Loss: {reg_loss.item():.4f}, "
                  f"Train diff risk: {self.accuracy:.4f}, "
                  f"Train high risk: {self.high_risk:.4f}, Train low risk: {self.low_risk:.4f}, ")

            self.evaluate(loader=self.valid_loader)

            info += (
                  f"Val diff risk: {self.accuracy:.4f}, "
                  f"Val high risk: {self.high_risk:.4f}, Val low risk: {self.low_risk:.4f}")

            print(info)


        elif self.config['task'] in ['regression']:
            info = (f"Epoch {epoch + 1}/{self.config['num_epochs']}, Loss: {avg_loss:.4f}, "
                  f"Task Loss: {task_loss.item():.4f}, Reg Loss: {reg_loss.item():.4f}, "
                  f"Train mse: {self.mse:.4f}, Train mae: {self.mae:.4f}, Train pcc: {self.pearson:.4f}, ")

            self.evaluate(loader=self.valid_loader)
            info += (f"Val mse: {self.mse:.4f}, Val mae: {self.mae:.4f}, Val pcc: {self.pearson:.4f}")

            print(info)

        elif self.config['task'] in ['autoencoder']:
            info = (f"Epoch {epoch + 1}/{self.config['num_epochs']}, Loss: {avg_loss:.4f}, "
                  f"Task Loss: {task_loss.item():.4f}, Reg Loss: {reg_loss.item():.4f}, "
                  f"Train rec Loss: {self.recon_loss:.4f}, ")

            self.evaluate(loader=self.valid_loader)
            info += (f"Train rec Loss: {self.recon_loss:.4f}")
            print(info)

        elif self.config['task'] in ['umap']:
            info = (f"Epoch {epoch + 1}/{self.config['num_epochs']}, Loss: {avg_loss:.4f}, "
                  f"Task Loss: {task_loss.item():.4f}, Reg Loss: {reg_loss.item():.4f}, "
                  f"Silhouette Loss: {self.silhouette_loss:.4f}, ")

            self.evaluate(loader=self.valid_loader)
            info += (f"Silhouette Loss: {self.silhouette_loss:.4f}")
            print(info)

    def train_nnea(self):

        # åˆå§‹åŒ–æ—©åœç›¸å…³å˜é‡ï¼ˆåŒæ—¶ç›‘æ§è®­ç»ƒæŸå¤±å’ŒéªŒè¯æŒ‡æ ‡ï¼‰
        self.best_metric = -float('inf') if self.config['task'] in ['classification', 'cox'] else float('inf')
        self.best_avg_loss = float('inf')  # æ–°å¢ï¼šè¿½è¸ªæœ€ä½³è®­ç»ƒæŸå¤±
        self.patience_counter_metric = 0  # éªŒè¯æŒ‡æ ‡æ— æ”¹å–„çš„è®¡æ•°å™¨
        self.patience_counter_loss = 0  # è®­ç»ƒæŸå¤±æ— æ”¹å–„çš„è®¡æ•°å™¨

        for epoch in range(self.config['num_epochs']):

            avg_loss, task_loss, reg_loss = self.one_epoch()
            self.evaluate(loader=self.train_loader)
            self.scheduler.step(avg_loss)

            # æ‰“å°è®­ç»ƒä¿¡æ¯
            self.print_process(epoch, task_loss, reg_loss, avg_loss)

            # å…³é”®ä¿®æ”¹ï¼šåŒæ—¶ç›‘æ§è®­ç»ƒæŸå¤±å’ŒéªŒè¯æŒ‡æ ‡
            improved_metric = self.save_model(epoch)  # éªŒè¯æŒ‡æ ‡æ˜¯å¦æå‡

            avg_loss, task_loss, reg_loss = self.calculate_loss(loader = self.valid_loader)
            improved_loss = avg_loss < self.best_avg_loss  # è®­ç»ƒæŸå¤±æ˜¯å¦é™ä½

            # æ›´æ–°æœ€ä½³æŸå¤±
            if improved_loss:
                self.best_avg_loss = avg_loss
                self.patience_counter_loss = 0
            else:
                self.patience_counter_loss += 1

            # æ›´æ–°æ—©åœè®¡æ•°å™¨ï¼ˆéªŒè¯æŒ‡æ ‡ï¼‰
            if improved_metric:
                self.patience_counter_metric += 1
            else:
                self.patience_counter_metric = 0


            # æ—©åœæ¡ä»¶ï¼šè®­ç»ƒæŸå¤±æˆ–éªŒè¯æŒ‡æ ‡è¿ç»­æ¶åŒ–
            # if (self.patience_counter_metric >= self.config['patience_metric'] and
            #         self.patience_counter_loss >= self.config['patience_loss']):
            if (self.patience_counter_loss >= self.config['patience_loss']):
                print(f"Early stopping at epoch {epoch}")
                break

    def evaluate_model(self, model, X, y):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½å¹¶è¿”å›æŒ‡æ ‡å­—å…¸"""
        pred = model.predict(X)

        if self.config['task'] == 'classification':
            metrics = {
                "Accuracy": accuracy_score(y, pred),
                "F1": f1_score(y, pred, average='weighted'),
            }
            try:
                proba = model.predict_proba(X)[:, 1]
                metrics["AUC"] = roc_auc_score(y, proba)
            except:
                metrics["AUC"] = None
        elif self.config['task'] == 'regression':  # å›å½’ä»»åŠ¡
            metrics = {
                "MSE": mean_squared_error(y, pred),
                "MAE": mean_absolute_error(y, pred),
                "R2": r2_score(y, pred)
            }
        return metrics, pred


    def train(self):

        if self.config['model'] in ["nnea"]:
            self.train_nnea()

        elif self.config['model'] in ["LR"]:

            if self.config['train_mod'] == "cross_validation":
                searcher = RandomizedSearchCV(
                    estimator=self.model["model"],
                    param_distributions=self.model["params"],
                    n_iter=15,
                    cv=self.loader.cv,
                    scoring=self.config["scoring"],
                    n_jobs=-self.config['n_jobs'],
                    verbose=self.config['verbose'],
                    random_state=self.config['seed']
                )

                searcher.fit(self.loader.X_train, self.loader.y_train)


                # ä¿å­˜æœ€ä½³æ¨¡å‹
                self.model = searcher.best_estimator_
                self.save_checkpoint()


            elif self.config['train_mod'] == "one_split":
                self.model.fit(self.loader.X_train, self.loader.y_train)
                test_metrics, test_pred = self.evaluate_model(self.model, self.loader.X_test, self.loader.y_test)
                print(classification_report(self.loader.y_test, test_pred))




class UMAP_Loss(nn.Module):
    def __init__(self, n_neighbors=15, min_dist=0.1):
        super().__init__()
        self.n_neighbors = n_neighbors
        self.min_dist = min_dist
        self.a, self.b = self._find_ab_params(min_dist)

    def _find_ab_params(self, min_dist):
        a = 1.0 / (min_dist ** 2)  # æŸ¯è¥¿åˆ†å¸ƒå‚æ•°è®¡ç®—[6](@ref)
        b = torch.log(torch.tensor(2.0))
        return a, b

    def forward(self, embeddings, data):
        # 1. åŠ¨æ€è°ƒæ•´é‚»å±…æ•°ï¼ˆå…³é”®ä¿®å¤ï¼ï¼‰
        n_samples = data.size(0)
        effective_k = min(self.n_neighbors + 1, n_samples)  # ç¡®ä¿ä¸è¶…è¿‡æ ·æœ¬æ•°

        # 2. é«˜ç»´ç©ºé—´ç›¸ä¼¼åº¦
        distances = torch.cdist(data, data)

        # å¤„ç†å°batchæƒ…å†µ
        if effective_k <= 1:  # æ— è¶³å¤Ÿé‚»å±…å¯è®¡ç®—
            return torch.tensor(0.0, device=data.device, requires_grad=True)

        # è·å–æœ€è¿‘çš„kä¸ªç‚¹ï¼ˆåŒ…æ‹¬è‡ªèº«ï¼‰
        _, indices = torch.topk(distances, effective_k, largest=False)

        # 3. æ„å»ºé‚»å±…æ©ç ï¼ˆæ’é™¤è‡ªèº«ï¼‰
        neighbor_mask = torch.zeros_like(distances, device=data.device)
        row_idx = torch.arange(n_samples).view(-1, 1).expand(-1, effective_k - 1)
        neighbor_mask[row_idx, indices[:, 1:]] = 1  # è·³è¿‡è‡ªèº«ï¼ˆç´¢å¼•0ï¼‰

        # 4. å¯¹ç§°åŒ–é‚»æ¥çŸ©é˜µï¼ˆUMAPæ ¸å¿ƒï¼‰
        neighbor_mask = neighbor_mask.float()
        sym_mask = (neighbor_mask + neighbor_mask.t()) > 0  # å–å¹¶é›†[1,4](@ref)

        # 5. è®¡ç®—é«˜ç»´ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨å±€éƒ¨è‡ªé€‚åº”å°ºåº¦ï¼‰
        local_scale = distances.gather(1, indices[:, 1:2]).mean(dim=1)  # è‡ªé€‚åº”Ïƒ[4](@ref)
        p_ij = sym_mask * torch.exp(-distances ** 2 / (local_scale.unsqueeze(1) * local_scale))
        p_ij = p_ij / torch.clamp(p_ij.sum(dim=1), min=1e-12).unsqueeze(1)

        # 6. ä½ç»´ç©ºé—´ç›¸ä¼¼åº¦
        low_dim_dist = torch.cdist(embeddings, embeddings)
        q_ij = 1.0 / (1 + self.a * low_dim_dist ** (2 * self.b))  # UMAPæ›²çº¿æ‹Ÿåˆ[1,6](@ref)

        # 7. äº¤å‰ç†µæŸå¤±ï¼ˆåŸå§‹UMAPè®¾è®¡ï¼‰[1,4,6](@ref)
        loss_pos = p_ij * torch.log(q_ij + 1e-7)
        loss_neg = (1 - p_ij) * torch.log(1 - q_ij + 1e-7)
        return -(loss_pos + loss_neg).mean()