from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import roc_auc_score, classification_report
from sklearn.model_selection import GridSearchCV, StratifiedKFold

import nnea as na
import numpy as np
import torch
import os
import warnings
import toml  # ç”¨äºè¯»å–tomlæ–‡ä»¶
import random

warnings.filterwarnings('ignore')

# è¯»å–DecisionTreeClassifieré…ç½®æ–‡ä»¶
try:
    config = toml.load("./config.toml")
except Exception as e:
    print(f"âŒ é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
    exit(1)

# è®¾ç½®æ‰€æœ‰éšæœºç§å­
def set_all_seeds(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    os.environ['PYTHONHASHSEED'] = str(seed)

# åœ¨æ•°æ®åŠ è½½ä¹‹å‰è°ƒç”¨
set_all_seeds(config['global']['seed'])

# åˆ›å»ºè¾“å‡ºç›®å½•
output_dir = config['global']['outdir']
os.makedirs(output_dir, exist_ok=True)

# è®¾ç½®æ—¥å¿—è¾“å‡ºåˆ°è¾“å‡ºç›®å½•
log_file = os.path.join(output_dir, "decision_tree_experiment.log")
na.setup_logging(log_file=log_file, experiment_name="decision_tree")
logger = na.get_logger(__name__)

logger.info("âš™ï¸ è¯»å–DecisionTreeClassifieré…ç½®æ–‡ä»¶...")
logger.info("âœ… é…ç½®æ–‡ä»¶è¯»å–æˆåŠŸ")
logger.info(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶å·²è®¾ç½®åˆ°: {log_file}")

# è®¾ç½®å…¨å±€éšæœºç§å­ï¼ˆåœ¨æ•°æ®åŠ è½½ä¹‹å‰ï¼‰
logger.info("ğŸ”§ è®¾ç½®å…¨å±€éšæœºç§å­...")
na.set_global_seed(config['global']['seed'])
logger.info("âœ… å…¨å±€éšæœºç§å­è®¾ç½®å®Œæˆ")

# æ•°æ®åŠ è½½
logger.info("ğŸ“‚ åŠ è½½æ•°æ®...")
try:
    nadata = na.nadata()
    nadata.load(filepath=config['global']['inputfl'])
    logger.info(f"âœ… é¢„å¤„ç†åçš„nadataå¯¹è±¡åŠ è½½å®Œæˆï¼Œæ•°æ®å½¢çŠ¶: {nadata.X.shape}")
except Exception as e:
    logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
    exit(1)

# æ•°æ®é¢„å¤„ç†
logger.info("ğŸ”§ æ•°æ®é¢„å¤„ç†...")
X = nadata.X

# ä½¿ç”¨é…ç½®ä¸­çš„é¢„å¤„ç†è®¾ç½®
preprocessing_config = config['decision_tree']['preprocessing']

# ä½¿ç”¨na.pp.fillnaå¤„ç†ç¼ºå¤±å€¼
if preprocessing_config['fill_na'] and np.isnan(X).any():
    logger.warning("âš ï¸ æ£€æµ‹åˆ°Xä¸­å­˜åœ¨NaNå€¼ï¼Œæ­£åœ¨è¿›è¡Œå¡«å……å¤„ç†...")
    X = na.pp.fillna(X, method=preprocessing_config['fill_method'])
    logger.info(f"   å¡«å……åNaNå€¼æ•°é‡: {np.isnan(X).sum()}")
else:
    logger.info("âœ… Xä¸­æœªæ£€æµ‹åˆ°NaNå€¼")

# ä½¿ç”¨na.pp.scaleè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†
if preprocessing_config['scale_data']:
    X = na.pp.scale(X, method=preprocessing_config['scale_method'])
    logger.info("âœ… æ•°æ®æ ‡å‡†åŒ–å®Œæˆ")

nadata.X = X

# å¤„ç†æ ‡ç­¾
logger.info("ğŸ·ï¸ å¤„ç†æ ‡ç­¾...")
y = nadata.Meta['response_NR']
y = y.map({'N': 0, 'R': 1})
nadata.Meta['target'] = y  # æ¨¡å‹é»˜è®¤ä½¿ç”¨target

# ç‰¹å¾é€‰æ‹©
if config['decision_tree']['feature_selection']:
    logger.info("ğŸ” ç‰¹å¾é€‰æ‹©...")
    nadata = na.fs.apply_feature_selection(
        nadata,
        method=config['decision_tree']['selection_method'],
        n_features=config['decision_tree']['n_features'],
        target_col='target',  # ä½¿ç”¨é»˜è®¤çš„targetåˆ—
        alpha=config['decision_tree']['selection_alpha']
    )
    logger.info(f"âœ… ç‰¹å¾é€‰æ‹©å®Œæˆï¼Œé€‰æ‹©ç‰¹å¾æ•°: {config['decision_tree']['n_features']}")

# æ•°æ®åˆ†å‰²
logger.info("âœ‚ï¸ è¿›è¡Œæ•°æ®åˆ†å‰²...")
try:
    nadata = na.pp.split_data(
        nadata,
        test_size=config['dataset']['test_size'],
        random_state=config['dataset']['random_state'],
        strategy="stratified"
    )
    logger.info("âœ… æ•°æ®åˆ†å‰²å®Œæˆ")
except Exception as e:
    logger.error(f"âŒ æ•°æ®åˆ†å‰²å¤±è´¥: {e}")

# ä½¿ç”¨na.pp.x_train_testå’Œna.pp.y_train_testè·å–è®­ç»ƒæµ‹è¯•é›†
X_train, X_test = na.pp.x_train_test(X, nadata)
y_train, y_test = na.pp.y_train_test(y, nadata)

logger.info(f"è®­ç»ƒé›†ç‰¹å¾å½¢çŠ¶: {X_train.shape}")
logger.info(f"æµ‹è¯•é›†ç‰¹å¾å½¢çŠ¶: {X_test.shape}")
logger.info(f"è®­ç»ƒé›†æ ‡ç­¾å½¢çŠ¶: {y_train.shape}")
logger.info(f"æµ‹è¯•é›†æ ‡ç­¾å½¢çŠ¶: {y_test.shape}")

# ä»é…ç½®æ–‡ä»¶æ„å»ºå‚æ•°ç½‘æ ¼
param_grid = {
    'criterion': config['decision_tree']['criterion'],
    'max_depth': config['decision_tree']['max_depth'] + [None],
    'min_samples_split': config['decision_tree']['min_samples_split'],
    'min_samples_leaf': config['decision_tree']['min_samples_leaf'],
    'max_features': config['decision_tree']['max_features'] + [None]
}

# æ„å»ºDecisionTreeClassifieræ¨¡å‹
dt = DecisionTreeClassifier(
    random_state=config['decision_tree']['random_state'],
    class_weight=config['decision_tree']['class_weight']
)

# ç½‘æ ¼æœç´¢äº¤å‰éªŒè¯
grid = GridSearchCV(
    dt,
    param_grid,
    cv=StratifiedKFold(
        n_splits=config['decision_tree']['cv_folds'],
        shuffle=True,
        random_state=config['decision_tree']['random_state']
    ),
    scoring=config['decision_tree']['cv_scoring'],
    n_jobs=config['decision_tree']['n_jobs'],
    verbose=config['training']['verbose']
)

logger.info("ğŸš€ å¼€å§‹ç½‘æ ¼æœç´¢è®­ç»ƒ...")
grid.fit(X_train, y_train)

logger.info(f"æœ€ä¼˜å‚æ•°: {grid.best_params_}")
logger.info(f"æœ€ä½³AUCå¾—åˆ†: {grid.best_score_}")

# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
y_pred = grid.predict(X_test)
y_proba = grid.predict_proba(X_test)[:, 1]

from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score
f1 = f1_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)
auc = roc_auc_score(y_test, y_proba)

logger.info(f"æµ‹è¯•é›†F1åˆ†æ•°: {f1:.4f}")
logger.info(f"æµ‹è¯•é›†å¬å›ç‡: {recall:.4f}")
logger.info(f"æµ‹è¯•é›†ç²¾ç¡®ç‡: {precision:.4f}")
logger.info(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {acc:.4f}")
logger.info(f"æµ‹è¯•é›†AUC: {auc:.4f}")
logger.info(f"æµ‹è¯•é›†åˆ†ç±»æŠ¥å‘Š:\n{classification_report(y_test, y_pred)}")

# æ„å»ºDecisionTreeClassifierç»“æœå­—å…¸
dt_result = {
    "best_params": grid.best_params_,
    "best_cv_auc": grid.best_score_,
    "test_auc": auc,
    "test_report": classification_report(y_test, y_pred, output_dict=True),
    "test_pred": y_pred,
    "test_proba": y_proba,
    "test_true": y_test.values,
    "best_model": grid.best_estimator_  # ä¿å­˜æœ€ä½³æ¨¡å‹
}

# ä¿å­˜åˆ°nadataå¯¹è±¡
if not hasattr(nadata, "Model"):
    nadata.Model = {}

nadata.Model["DecisionTreeClassifier"] = dt_result

# ä¿å­˜nadataå¯¹è±¡åˆ°é…ç½®çš„è¾“å‡ºç›®å½•
output_file = os.path.join(output_dir, config['global']['outputfl'])
nadata.save(output_file, format=config['training']['save_format'], save_data=config['training']['save_data'])
logger.info(f"âœ… å·²å®Œæˆdecision treeæ¨¡å‹è®­ç»ƒï¼Œå¹¶ä¿å­˜åˆ°: {output_file}")

# ä¿å­˜é…ç½®ä¿¡æ¯
config_file = os.path.join(output_dir, "decision_tree_config.toml")
with open(config_file, 'w', encoding='utf-8') as f:
    toml.dump(config, f)
logger.info(f"âœ… é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ°: {config_file}")

# ä¿å­˜è®­ç»ƒç»“æœæ‘˜è¦
summary_file = os.path.join(output_dir, "training_summary.txt")
with open(summary_file, 'w', encoding='utf-8') as f:
    f.write("LogisticRegression è®­ç»ƒç»“æœæ‘˜è¦\n")
    f.write("=" * 50 + "\n")
    f.write(f"æœ€ä¼˜å‚æ•°: {grid.best_params_}\n")
    f.write(f"æœ€ä½³äº¤å‰éªŒè¯AUC: {grid.best_score_:.4f}\n")
    f.write(f"æµ‹è¯•é›†AUC: {auc:.4f}\n")
    f.write(f"æµ‹è¯•é›†F1åˆ†æ•°: {f1:.4f}\n")
    f.write(f"æµ‹è¯•é›†å¬å›ç‡: {recall:.4f}\n")
    f.write(f"æµ‹è¯•é›†ç²¾ç¡®ç‡: {precision:.4f}\n")
    f.write(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {acc:.4f}\n")
    f.write(f"è®­ç»ƒé›†å½¢çŠ¶: {X_train.shape}\n")
    f.write(f"æµ‹è¯•é›†å½¢çŠ¶: {X_test.shape}\n")
    f.write("\nåˆ†ç±»æŠ¥å‘Š:\n")
    f.write(classification_report(y_test, y_pred))

logger.info(f"âœ… è®­ç»ƒç»“æœæ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")
logger.info("ğŸ‰ å®éªŒå®Œæˆï¼")