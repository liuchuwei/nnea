import nnea as na
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.preprocessing import StandardScaler
import numpy as np
import warnings
import threading
import time
import logging
import os
import sys
from datetime import datetime
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
import queue
warnings.filterwarnings('ignore')

# è®¾ç½®æ—¥å¿—è®°å½•
def setup_logging(log_dir="experiment/tumor_imm/ccRCC_imm/logs"):
    """è®¾ç½®æ—¥å¿—è®°å½•ç³»ç»Ÿ"""
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
        print(f"âœ… åˆ›å»ºæ—¥å¿—ç›®å½•: {log_dir}")
    
    # åˆ›å»ºæ—¥å¿—æ–‡ä»¶åï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = os.path.join(log_dir, f"training_log_{timestamp}.log")
    
    # æ¸…é™¤ä¹‹å‰çš„æ—¥å¿—é…ç½®
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    
    # é…ç½®æ—¥å¿—è®°å½•å™¨
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8', mode='w'),
            logging.StreamHandler()
        ],
        force=True
    )
    
    logger = logging.getLogger(__name__)
    
    # è®°å½•æ—¥å¿—æ–‡ä»¶è·¯å¾„
    print(f"ğŸ“ æ—¥å¿—æ–‡ä»¶ä¿å­˜è·¯å¾„: {os.path.abspath(log_file)}")
    logger.info(f"æ—¥å¿—æ–‡ä»¶ä¿å­˜è·¯å¾„: {os.path.abspath(log_file)}")
    
    return logger

# çº¿ç¨‹å®‰å…¨çš„æ—¥å¿—è®°å½•å™¨
class ThreadSafeLogger:
    def __init__(self, logger):
        self.logger = logger
        self.lock = threading.Lock()
    
    def info(self, message):
        with self.lock:
            self.logger.info(message)
    
    def warning(self, message):
        with self.lock:
            self.logger.warning(message)
    
    def error(self, message):
        with self.lock:
            self.logger.error(message)
    
    def debug(self, message):
        with self.lock:
            self.logger.debug(message)

# è®­ç»ƒå•ä¸ªæ¨¡å‹çš„å‡½æ•°
def train_single_model(name, classifier, param_grid, X_train, y_train, X_test, y_test, logger, progress_queue):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹çš„å‡½æ•°"""
    try:
        logger.info(f"å¼€å§‹è®­ç»ƒ {name}")
        logger.info(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: X_train={X_train.shape}, y_train={y_train.shape}")
        logger.info(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: X_test={X_test.shape}, y_test={y_test.shape}")
        logger.info(f"å‚æ•°ç½‘æ ¼å¤§å°: {len([k for k in param_grid.keys()])} ä¸ªå‚æ•°")
        
        # ç½‘æ ¼æœç´¢äº¤å‰éªŒè¯
        grid = GridSearchCV(
            classifier,
            param_grid,
            cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
            scoring='roc_auc',
            n_jobs=1,  # å•ä¸ªçº¿ç¨‹å†…ä¸ä½¿ç”¨å¤šè¿›ç¨‹
            verbose=0
        )
        
        logger.info(f"å¼€å§‹ç½‘æ ¼æœç´¢ï¼Œäº¤å‰éªŒè¯æŠ˜æ•°: 5")
        # è®­ç»ƒæ¨¡å‹
        grid.fit(X_train, y_train)
        
        logger.info(f"âœ… {name} è®­ç»ƒå®Œæˆ")
        logger.info(f"æœ€ä¼˜å‚æ•°ï¼š{grid.best_params_}")
        logger.info(f"æœ€ä½³äº¤å‰éªŒè¯AUCå¾—åˆ†ï¼š{grid.best_score_:.4f}")
        
        # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
        logger.info(f"å¼€å§‹åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° {name}")
        y_pred = grid.predict(X_test)
        
        # è·å–é¢„æµ‹æ¦‚ç‡
        if hasattr(grid.best_estimator_, "predict_proba"):
            y_proba = grid.predict_proba(X_test)[:, 1]
            logger.info(f"ä½¿ç”¨ predict_proba æ–¹æ³•è·å–é¢„æµ‹æ¦‚ç‡")
        elif hasattr(grid.best_estimator_, "decision_function"):
            # å¯¹äºSVMï¼Œä½¿ç”¨decision_function
            y_proba = grid.decision_function(X_test)
            # ç¡®ä¿æ¦‚ç‡å€¼åœ¨[0,1]èŒƒå›´å†…
            y_proba = (y_proba - y_proba.min()) / (y_proba.max() - y_proba.min())
            logger.info(f"ä½¿ç”¨ decision_function æ–¹æ³•è·å–é¢„æµ‹æ¦‚ç‡")
        else:
            # å¦‚æœæ²¡æœ‰æ¦‚ç‡é¢„æµ‹æ–¹æ³•ï¼Œä½¿ç”¨å…¨0
            y_proba = np.zeros_like(y_pred, dtype=float)
            logger.info(f"æ¨¡å‹ä¸æ”¯æŒæ¦‚ç‡é¢„æµ‹ï¼Œä½¿ç”¨é›¶æ¦‚ç‡")
        
        # è®¡ç®—AUC
        test_auc = roc_auc_score(y_test, y_proba)
        
        logger.info(f"æµ‹è¯•é›†AUCï¼š{test_auc:.4f}")
        logger.info(f"é¢„æµ‹å‡†ç¡®ç‡ï¼š{(y_pred == y_test).mean():.4f}")
        
        # æ„å»ºç»“æœå­—å…¸
        result = {
            "best_params": grid.best_params_,
            "best_cv_auc": grid.best_score_,
            "test_auc": test_auc,
            "test_report": classification_report(y_test, y_pred, output_dict=True),
            "test_pred": y_pred,
            "test_proba": y_proba,
            "test_true": y_test.values,
            "best_model": grid.best_estimator_
        }
        
        # é€šçŸ¥è¿›åº¦æ›´æ–°
        progress_queue.put(("success", name, result))
        logger.info(f"âœ… {name} ç»“æœå·²ä¿å­˜")
        
        return name, result
        
    except Exception as e:
        error_msg = f"âŒ {name} è®­ç»ƒå¤±è´¥: {str(e)}"
        logger.error(error_msg)
        progress_queue.put(("error", name, str(e)))
        return name, None

# ä¸»å‡½æ•°
def main():
    # è®¾ç½®æ—¥å¿—è®°å½•
    logger = setup_logging()
    thread_logger = ThreadSafeLogger(logger)
    
    logger.info("ğŸš€ å¼€å§‹å¤šçº¿ç¨‹æ¨¡å‹è®­ç»ƒå®éªŒ")
    logger.info("=" * 60)
    logger.info(f"å®éªŒå¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"Pythonç‰ˆæœ¬: {sys.version}")
    logger.info(f"å·¥ä½œç›®å½•: {os.getcwd()}")
    logger.info("=" * 60)
    
    # åŠ è½½é¢„å¤„ç†åä¿å­˜çš„ccRCCå…ç–«æ²»ç–—æ•°æ®
    nadata = na.nadata()
    nadata.load(filepath="experiment/tumor_imm/ccRCC_imm_exp.pkl")
    logger.info(f"âœ… é¢„å¤„ç†åçš„nadataå¯¹è±¡åŠ è½½å®Œæˆï¼Œæ•°æ®å½¢çŠ¶: {nadata.X.shape}")
    
    # è·å–ç‰¹å¾å’Œæ ‡ç­¾
    X = nadata.X
    
    # ä½¿ç”¨na.pp.fillnaå¤„ç†ç¼ºå¤±å€¼
    if np.isnan(X).any():
        logger.warning("âš ï¸ æ£€æµ‹åˆ°Xä¸­å­˜åœ¨NaNå€¼ï¼Œæ­£åœ¨è¿›è¡Œå¡«å……å¤„ç†...")
        X = na.pp.fillna(X, method="mean")
    else:
        logger.info("âœ… Xä¸­æœªæ£€æµ‹åˆ°NaNå€¼")
    
    # ä½¿ç”¨na.pp.scaleè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†
    X = na.pp.scale(X, method="standard")
    
    y = nadata.Meta['response_NR']
    # å°†yä¸­çš„'N'æ˜ å°„ä¸º0ï¼Œ'R'æ˜ å°„ä¸º1
    y = y.map({'N': 0, 'R': 1})
    
    # ä½¿ç”¨na.pp.x_train_testå’Œna.pp.y_train_testè·å–è®­ç»ƒæµ‹è¯•é›†
    X_train, X_test = na.pp.x_train_test(X, nadata)
    y_train, y_test = na.pp.y_train_test(y, nadata)
    
    logger.info(f"è®­ç»ƒé›†ç‰¹å¾å½¢çŠ¶: {X_train.shape}")
    logger.info(f"æµ‹è¯•é›†ç‰¹å¾å½¢çŠ¶: {X_test.shape}")
    logger.info(f"è®­ç»ƒé›†æ ‡ç­¾å½¢çŠ¶: {y_train.shape}")
    logger.info(f"æµ‹è¯•é›†æ ‡ç­¾å½¢çŠ¶: {y_test.shape}")
    
    # å®šä¹‰æ‰€æœ‰åˆ†ç±»å™¨çš„è¶…å‚æ•°æœç´¢ç©ºé—´
    param_grids = {
        'LogisticRegression': {
            'C': [0.1, 1, 10, 100],
            'penalty': ['l1', 'l2'],
            'solver': ['liblinear', 'saga'],
            'max_iter': [1000]
        },
        'DecisionTreeClassifier': {
            'criterion': ['gini', 'entropy', 'log_loss'],
            'max_depth': [None, 3, 5, 10, 20],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4],
            'max_features': [None, 'sqrt', 'log2']
        },
        'RandomForestClassifier': {
            'n_estimators': [50, 100, 200],
            'max_depth': [None, 10, 20, 30],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4],
            'max_features': ['sqrt', 'log2', None]
        },
        'AdaBoostClassifier': {
            'n_estimators': [50, 100, 200],
            'learning_rate': [0.01, 0.1, 0.5, 1.0],
            'algorithm': ['SAMME', 'SAMME.R']
        },
        'MLPClassifier': {
            'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],
            'activation': ['relu', 'tanh'],
            'alpha': [0.0001, 0.001, 0.01],
            'learning_rate': ['constant', 'adaptive'],
            'max_iter': [1000]
        },
        'LinearSVM': {
            'C': [0.1, 1, 10, 100],
            'penalty': ['l1', 'l2'],
            'loss': ['hinge', 'squared_hinge'],
            'max_iter': [1000]
        },
        'RBFSVM': {
            'C': [0.1, 1, 10, 100],
            'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],
            'kernel': ['rbf']
        }
    }
    
    # å®šä¹‰æ‰€æœ‰åˆ†ç±»å™¨
    classifiers = {
        'LogisticRegression': LogisticRegression(random_state=42),
        'DecisionTreeClassifier': DecisionTreeClassifier(random_state=42),
        'RandomForestClassifier': RandomForestClassifier(random_state=42),
        'AdaBoostClassifier': AdaBoostClassifier(random_state=42),
        'MLPClassifier': MLPClassifier(random_state=42, max_iter=1000),
        'LinearSVM': LinearSVC(random_state=42, max_iter=1000),
        'RBFSVM': SVC(random_state=42, probability=True)
    }
    
    # åˆå§‹åŒ–ç»“æœå­˜å‚¨
    if not hasattr(nadata, "Model"):
        nadata.Model = {}
    
    # åˆ›å»ºè¿›åº¦é˜Ÿåˆ—
    progress_queue = queue.Queue()
    
    # åˆ›å»ºè¿›åº¦æ¡
    total_models = len(classifiers)
    pbar = tqdm(total=total_models, desc="è®­ç»ƒè¿›åº¦", unit="æ¨¡å‹")
    
    # å­˜å‚¨æ‰€æœ‰ä»»åŠ¡çš„ç»“æœ
    results = {}
    
    # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¤šçº¿ç¨‹è®­ç»ƒ
    logger.info(f"å¼€å§‹å¤šçº¿ç¨‹è®­ç»ƒï¼Œçº¿ç¨‹æ± å¤§å°: 4")
    logger.info(f"å¾…è®­ç»ƒæ¨¡å‹æ•°é‡: {len(classifiers)}")
    logger.info("æ¨¡å‹åˆ—è¡¨: " + ", ".join(classifiers.keys()))
    
    with ThreadPoolExecutor(max_workers=10) as executor:
        # æäº¤æ‰€æœ‰è®­ç»ƒä»»åŠ¡
        future_to_name = {}
        for name, classifier in classifiers.items():
            param_grid = param_grids[name]
            logger.info(f"æäº¤è®­ç»ƒä»»åŠ¡: {name}")
            future = executor.submit(
                train_single_model,
                name, classifier, param_grid,
                X_train, y_train, X_test, y_test,
                thread_logger, progress_queue
            )
            future_to_name[future] = name
        
        # ç›‘æ§è¿›åº¦
        completed = 0
        while completed < total_models:
            try:
                # æ£€æŸ¥è¿›åº¦é˜Ÿåˆ—
                status, name, result = progress_queue.get(timeout=1)
                if status == "success":
                    results[name] = result
                    nadata.Model[name] = result
                    pbar.update(1)
                    completed += 1
                    pbar.set_postfix({"å½“å‰": name, "å®Œæˆ": f"{completed}/{total_models}"})
                elif status == "error":
                    pbar.update(1)
                    completed += 1
                    pbar.set_postfix({"å½“å‰": name, "å®Œæˆ": f"{completed}/{total_models}", "çŠ¶æ€": "å¤±è´¥"})
            except queue.Empty:
                # æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡å®Œæˆ
                for future in as_completed(future_to_name):
                    name = future_to_name[future]
                    if name not in results:
                        # å¦‚æœé˜Ÿåˆ—ä¸­æ²¡æœ‰ç»“æœï¼Œè¯´æ˜ä»»åŠ¡å¤±è´¥
                        pbar.update(1)
                        completed += 1
                        pbar.set_postfix({"å½“å‰": name, "å®Œæˆ": f"{completed}/{total_models}", "çŠ¶æ€": "å¤±è´¥"})
                continue
    
    pbar.close()
    
    # ä¿å­˜nadataå¯¹è±¡åˆ°æ–‡ä»¶
    save_path = "experiment/tumor_imm/ccRCC_imm_exp.pkl"
    logger.info(f"ä¿å­˜å®éªŒç»“æœåˆ°: {os.path.abspath(save_path)}")
    nadata.save(save_path, format="pickle", save_data=True)
    logger.info("=" * 60)
    logger.info("æ‰€æœ‰åˆ†ç±»å™¨è®­ç»ƒå®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ°nadataå¯¹è±¡ä¸­")
    logger.info(f"å®éªŒç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 60)
    
    # æ‰“å°æ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½æ¯”è¾ƒ
    logger.info("\nğŸ“Š æ‰€æœ‰æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ:")
    logger.info("-" * 80)
    logger.info(f"{'æ¨¡å‹åç§°':<20} {'CV AUC':<10} {'æµ‹è¯•AUC':<10}")
    logger.info("-" * 80)
    
    for name in classifiers.keys():
        if name in nadata.Model:
            cv_auc = nadata.Model[name]["best_cv_auc"]
            test_auc = nadata.Model[name]["test_auc"]
            logger.info(f"{name:<20} {cv_auc:<10.4f} {test_auc:<10.4f}")
    
    logger.info("-" * 80)
    logger.info("âœ… æ‰€æœ‰åˆ†ç±»å™¨è®­ç»ƒå’Œè¯„ä¼°å®Œæˆï¼")
    
    return nadata

if __name__ == "__main__":
    main() 